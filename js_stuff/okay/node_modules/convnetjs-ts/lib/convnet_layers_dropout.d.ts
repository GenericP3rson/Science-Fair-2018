import { Vol } from "./convnet_vol";
import { LayerBase, LayerOptions, ILayer, LayerJSON, ParamsAndGrads } from "./layers";
export interface DorpoutLayerOptions extends LayerOptions {
    /** <required> */
    drop_prob: number;
}
/**
 * An inefficient dropout layer
 * Note this is not most efficient implementation since the layer before
 * computed all these activations and now we're just going to drop them :(
 * same goes for backward pass. Also, if we wanted to be efficient at test time
 * we could equivalently be clever and upscale during train and copy pointers during test
 * todo: make more efficient.
 */
export declare class DropoutLayer extends LayerBase implements ILayer {
    in_act: Vol;
    drop_prob: number;
    dropped: boolean[];
    out_act: Vol;
    constructor(opt?: LayerOptions);
    forward(V: Vol, is_training?: boolean): Vol;
    backward(): void;
    getParamsAndGrads(): ParamsAndGrads[];
    toJSON(): LayerJSON;
    fromJSON(json: LayerJSON): void;
}
