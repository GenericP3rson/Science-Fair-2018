Object.defineProperty(exports, "__esModule", { value: true });
var tslib_1 = require("tslib");
var convnet_vol_1 = require("./convnet_vol");
var layers_1 = require("./layers");
var util = require("./convnet_util");
/** This is a classifier, with N discrete classes from 0 to N-1
 * it gets a stream of N incoming numbers and computes the softmax
 * function (exponentiate and normalize to sum to 1 as probabilities should)
 */
var SoftmaxLayer = (function (_super) {
    tslib_1.__extends(SoftmaxLayer, _super);
    function SoftmaxLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var lopt = opt;
        _this = _super.call(this, lopt) || this;
        // computed
        _this.num_inputs = lopt.in_sx * lopt.in_sy * lopt.in_depth;
        _this.out_depth = _this.num_inputs;
        _this.out_sx = 1;
        _this.out_sy = 1;
        _this.layer_type = 'softmax';
        return _this;
    }
    SoftmaxLayer.prototype.forward = function (V) {
        this.in_act = V;
        var A = new convnet_vol_1.Vol(1, 1, this.out_depth, 0.0);
        // compute max activation
        var as = V.w;
        var amax = V.w[0];
        for (var i = 1; i < this.out_depth; i++) {
            if (as[i] > amax) {
                amax = as[i];
            }
        }
        // compute exponentials (carefully to not blow up)
        var es = util.zeros(this.out_depth);
        var esum = 0.0;
        for (var i = 0; i < this.out_depth; i++) {
            var e = Math.exp(as[i] - amax);
            esum += e;
            es[i] = e;
        }
        // normalize and output to sum to one
        for (var i = 0; i < this.out_depth; i++) {
            es[i] /= esum;
            A.w[i] = es[i];
        }
        this.es = es; // save these for backprop
        this.out_act = A;
        return this.out_act;
    };
    SoftmaxLayer.prototype.backward = function (y) {
        // compute and accumulate gradient wrt weights and bias of this layer
        var x = this.in_act;
        x.dw = util.zeros(x.w.length); // zero out the gradient of input Vol
        for (var i = 0; i < this.out_depth; i++) {
            var indicator = i === y ? 1.0 : 0.0;
            var mul = -(indicator - this.es[i]);
            x.dw[i] = mul;
        }
        // loss is the class negative log likelihood
        return -Math.log(this.es[y]);
    };
    SoftmaxLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    SoftmaxLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.num_inputs = this.num_inputs;
        return json;
    };
    SoftmaxLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.num_inputs = json.num_inputs;
    };
    return SoftmaxLayer;
}(layers_1.LayerBase));
exports.SoftmaxLayer = SoftmaxLayer;
/**
 * implements an L2 regression cost layer,
 * so penalizes \sum_i(||x_i - y_i||^2), where x is its input
 * and y is the user-provided array of "correct" values.
 */
var RegressionLayer = (function (_super) {
    tslib_1.__extends(RegressionLayer, _super);
    function RegressionLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var lopt = opt;
        _this = _super.call(this, lopt) || this;
        // computed
        _this.num_inputs = lopt.in_sx * lopt.in_sy * lopt.in_depth;
        _this.out_depth = _this.num_inputs;
        _this.out_sx = 1;
        _this.out_sy = 1;
        _this.layer_type = 'regression';
        return _this;
    }
    RegressionLayer.prototype.forward = function (V) {
        this.in_act = V;
        this.out_act = V;
        return V; // identity function
    };
    // y is a list here of size num_inputs
    // or it can be a number if only one value is regressed
    // or it can be a struct {dim: i, val: x} where we only want to
    // regress on dimension i and asking it to have value x
    RegressionLayer.prototype.backward = function (y) {
        // compute and accumulate gradient wrt weights and bias of this layer
        var x = this.in_act;
        x.dw = util.zeros(x.w.length); // zero out the gradient of input Vol
        var loss = 0.0;
        if (y instanceof Array || y instanceof Float64Array) {
            for (var i = 0; i < this.out_depth; i++) {
                var dy = x.w[i] - y[i];
                x.dw[i] = dy;
                loss += 0.5 * dy * dy;
            }
        }
        else if (typeof y === 'number') {
            // lets hope that only one number is being regressed
            var dy = x.w[0] - y;
            x.dw[0] = dy;
            loss += 0.5 * dy * dy;
        }
        else {
            // assume it is a struct with entries .dim and .val
            // and we pass gradient only along dimension dim to be equal to val
            var i = y.dim;
            var yi = y.val;
            var dy = x.w[i] - yi;
            x.dw[i] = dy;
            loss += 0.5 * dy * dy;
        }
        return loss;
    };
    RegressionLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    RegressionLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.num_inputs = this.num_inputs;
        return json;
    };
    RegressionLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.num_inputs = json.num_inputs;
    };
    return RegressionLayer;
}(layers_1.LayerBase));
exports.RegressionLayer = RegressionLayer;
var SVMLayer = (function (_super) {
    tslib_1.__extends(SVMLayer, _super);
    function SVMLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var lopt = opt;
        _this = _super.call(this, lopt) || this;
        // computed
        _this.num_inputs = lopt.in_sx * lopt.in_sy * lopt.in_depth;
        _this.out_depth = _this.num_inputs;
        _this.out_sx = 1;
        _this.out_sy = 1;
        _this.layer_type = 'svm';
        return _this;
    }
    SVMLayer.prototype.forward = function (V) {
        this.in_act = V;
        this.out_act = V; // nothing to do, output raw scores
        return V;
    };
    SVMLayer.prototype.backward = function (y) {
        // compute and accumulate gradient wrt weights and bias of this layer
        var x = this.in_act;
        x.dw = util.zeros(x.w.length); // zero out the gradient of input Vol
        // we're using structured loss here, which means that the score
        // of the ground truth should be higher than the score of any other
        // class, by a margin
        var yscore = x.w[y]; // score of ground truth
        var margin = 1.0;
        var loss = 0.0;
        for (var i = 0; i < this.out_depth; i++) {
            if (y === i) {
                continue;
            }
            var ydiff = -yscore + x.w[i] + margin;
            if (ydiff > 0) {
                // violating dimension, apply loss
                x.dw[i] += 1;
                x.dw[y] -= 1;
                loss += ydiff;
            }
        }
        return loss;
    };
    SVMLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    SVMLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.num_inputs = this.num_inputs;
        return json;
    };
    SVMLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.num_inputs = json.num_inputs;
    };
    return SVMLayer;
}(layers_1.LayerBase));
exports.SVMLayer = SVMLayer;
//# sourceMappingURL=convnet_layers_loss.js.map