var convnetjs =
/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// identity function for calling harmony imports with the correct context
/******/ 	__webpack_require__.i = function(value) { return value; };
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, {
/******/ 				configurable: false,
/******/ 				enumerable: true,
/******/ 				get: getter
/******/ 			});
/******/ 		}
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 11);
/******/ })
/************************************************************************/
/******/ ([
/* 0 */
/***/ (function(module, exports) {

Object.defineProperty(exports, "__esModule", { value: true });
// Random number utilities
var return_v = false;
var v_val = 0.0;
function gaussRandom() {
    if (return_v) {
        return_v = false;
        return v_val;
    }
    var u = 2 * Math.random() - 1;
    var v = 2 * Math.random() - 1;
    var r = u * u + v * v;
    if (r === 0 || r > 1) {
        return gaussRandom();
    }
    var c = Math.sqrt(-2 * Math.log(r) / r);
    v_val = v * c; // cache this
    return_v = true;
    return u * c;
}
exports.gaussRandom = gaussRandom;
function randf(a, b) { return Math.random() * (b - a) + a; }
exports.randf = randf;
function randi(a, b) { return Math.floor(Math.random() * (b - a) + a); }
exports.randi = randi;
function randn(mu, std) { return mu + gaussRandom() * std; }
exports.randn = randn;
// Array utilities
function zeros(n) {
    if (typeof (n) === 'undefined' || isNaN(n)) {
        return [];
    }
    if (typeof ArrayBuffer === 'undefined') {
        // lacking browser support
        var arr = new Array(n);
        for (var i = 0; i < n; i++) {
            arr[i] = 0;
        }
        return arr;
    }
    else {
        return new Float64Array(n);
    }
}
exports.zeros = zeros;
function arrContains(arr, elt) {
    for (var i = 0, n = arr.length; i < n; i++) {
        if (arr[i] === elt) {
            return true;
        }
    }
    return false;
}
exports.arrContains = arrContains;
function arrUnique(arr) {
    var b = [];
    for (var i = 0, n = arr.length; i < n; i++) {
        if (!arrContains(b, arr[i])) {
            b.push(arr[i]);
        }
    }
    return b;
}
exports.arrUnique = arrUnique;
/** return max and min of a given non-empty array. */
function maxmin(w) {
    if (w.length === 0) {
        return {};
    } // ... ;s
    var maxv = w[0];
    var minv = w[0];
    var maxi = 0;
    var mini = 0;
    var n = w.length;
    for (var i = 1; i < n; i++) {
        if (w[i] > maxv) {
            maxv = w[i];
            maxi = i;
        }
        if (w[i] < minv) {
            minv = w[i];
            mini = i;
        }
    }
    return { maxi: maxi, maxv: maxv, mini: mini, minv: minv, dv: maxv - minv };
}
exports.maxmin = maxmin;
/** create random permutation of numbers, in range [0...n-1] */
function randperm(n) {
    var i = n, j = 0, temp;
    var array = [];
    for (var q = 0; q < n; q++) {
        array[q] = q;
    }
    while (i--) {
        j = Math.floor(Math.random() * (i + 1));
        temp = array[i];
        array[i] = array[j];
        array[j] = temp;
    }
    return array;
}
exports.randperm = randperm;
/** sample from list lst according to probabilities in list probs
 * the two lists are of same size, and probs adds up to 1
 */
function weightedSample(lst, probs) {
    var p = randf(0, 1.0);
    var cumprob = 0.0;
    for (var k = 0, n = lst.length; k < n; k++) {
        cumprob += probs[k];
        if (p < cumprob) {
            return lst[k];
        }
    }
}
exports.weightedSample = weightedSample;
/**
 * syntactic sugar function for getting default parameter values
 */
function getopt(opt, field_name, default_value) {
    if (typeof field_name === 'string') {
        // case of single string
        var ret = (typeof opt[field_name] !== 'undefined') ? opt[field_name] : default_value;
        return Number(ret);
    }
    else {
        // assume we are given a list of string instead
        var ret = default_value;
        for (var i = 0; i < field_name.length; i++) {
            var f = field_name[i];
            if (typeof opt[f] !== 'undefined') {
                ret = Number(opt[f]); // overwrite return value
            }
        }
        return ret;
    }
}
exports.getopt = getopt;
function assert(condition, message) {
    if (!condition) {
        message = message || "Assertion failed";
        if (typeof Error !== "undefined") {
            throw new Error(message);
        }
        throw message; // Fallback
    }
}
exports.assert = assert;
//# sourceMappingURL=convnet_util.js.map

/***/ }),
/* 1 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var util = __webpack_require__(0);
/** Vol is the basic building block of all data in a net.
 * it is essentially just a 3D volume of numbers, with a
 * width (sx), height (sy), and depth (depth).
 * it is used to hold data for all filters, all volumes,
 * all weights, and also stores all gradients w.r.t.
 * the data. c is optionally a value to initialize the volume
 * with. If c is missing, fills the Vol with random numbers.
*/
var Vol = (function () {
    function Vol(sx_or_list, sy, depth, c) {
        // this is how you check if a variable is an array. Oh, Javascript :)
        // Object.prototype.toString.call(sx_or_list) === '[object Array]'
        if (Array.isArray(sx_or_list)) {
            // we were given a list in sx, assume 1D volume and fill it up
            var list = sx_or_list;
            this.sx = 1;
            this.sy = 1;
            this.depth = list.length;
            // we have to do the following copy because we want to use
            // fast typed arrays, not an ordinary javascript array
            this.w = util.zeros(this.depth);
            this.dw = util.zeros(this.depth);
            for (var i = 0; i < this.depth; i++) {
                this.w[i] = list[i];
            }
        }
        else {
            // we were given dimensions of the vol
            var sx = sx_or_list;
            this.sx = sx;
            this.sy = sy;
            this.depth = depth;
            var n = sx * sy * depth;
            this.w = util.zeros(n);
            this.dw = util.zeros(n);
            if (typeof c === 'undefined') {
                // weight normalization is done to equalize the output
                // variance of every neuron, otherwise neurons with a lot
                // of incoming connections have outputs of larger variance
                var scale = Math.sqrt(1.0 / (sx * sy * depth));
                for (var i = 0; i < n; i++) {
                    this.w[i] = util.randn(0.0, scale);
                }
            }
            else {
                for (var i = 0; i < n; i++) {
                    this.w[i] = c;
                }
            }
        }
    }
    Vol.prototype.get = function (x, y, d) {
        var ix = ((this.sx * y) + x) * this.depth + d;
        return this.w[ix];
    };
    Vol.prototype.set = function (x, y, d, v) {
        var ix = ((this.sx * y) + x) * this.depth + d;
        this.w[ix] = v;
    };
    Vol.prototype.add = function (x, y, d, v) {
        var ix = ((this.sx * y) + x) * this.depth + d;
        this.w[ix] += v;
    };
    Vol.prototype.get_grad = function (x, y, d) {
        var ix = ((this.sx * y) + x) * this.depth + d;
        return this.dw[ix];
    };
    Vol.prototype.set_grad = function (x, y, d, v) {
        var ix = ((this.sx * y) + x) * this.depth + d;
        this.dw[ix] = v;
    };
    Vol.prototype.add_grad = function (x, y, d, v) {
        var ix = ((this.sx * y) + x) * this.depth + d;
        this.dw[ix] += v;
    };
    Vol.prototype.cloneAndZero = function () { return new Vol(this.sx, this.sy, this.depth, 0.0); };
    Vol.prototype.clone = function () {
        var V = new Vol(this.sx, this.sy, this.depth, 0.0);
        var n = this.w.length;
        for (var i = 0; i < n; i++) {
            V.w[i] = this.w[i];
        }
        return V;
    };
    Vol.prototype.addFrom = function (V) { for (var k = 0; k < this.w.length; k++) {
        this.w[k] += V.w[k];
    } };
    Vol.prototype.addFromScaled = function (V, a) { for (var k = 0; k < this.w.length; k++) {
        this.w[k] += a * V.w[k];
    } };
    Vol.prototype.setConst = function (a) { for (var k = 0; k < this.w.length; k++) {
        this.w[k] = a;
    } };
    Vol.prototype.toJSON = function () {
        // todo: we may want to only save d most significant digits to save space
        var json = { sx: this.sx, sy: this.sy, depth: this.depth, w: this.w };
        return json;
        // we wont back up gradients to save space
    };
    Vol.prototype.fromJSON = function (json) {
        this.sx = json.sx;
        this.sy = json.sy;
        this.depth = json.depth;
        var n = this.sx * this.sy * this.depth;
        this.w = util.zeros(n);
        this.dw = util.zeros(n);
        // copy over the elements.
        for (var i = 0; i < n; i++) {
            this.w[i] = json.w[i];
        }
    };
    return Vol;
}());
exports.Vol = Vol;
//# sourceMappingURL=convnet_vol.js.map

/***/ }),
/* 2 */
/***/ (function(module, exports) {

Object.defineProperty(exports, "__esModule", { value: true });
var LayerBase = (function () {
    function LayerBase(opt) {
        if (!opt) {
            return;
        }
    }
    return LayerBase;
}());
exports.LayerBase = LayerBase;
//# sourceMappingURL=layers.js.map

/***/ }),
/* 3 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
Object.defineProperty(__webpack_exports__, "__esModule", { value: true });
/* harmony export (immutable) */ __webpack_exports__["__extends"] = __extends;
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "__assign", function() { return __assign; });
/* harmony export (immutable) */ __webpack_exports__["__rest"] = __rest;
/* harmony export (immutable) */ __webpack_exports__["__decorate"] = __decorate;
/* harmony export (immutable) */ __webpack_exports__["__param"] = __param;
/* harmony export (immutable) */ __webpack_exports__["__metadata"] = __metadata;
/* harmony export (immutable) */ __webpack_exports__["__awaiter"] = __awaiter;
/* harmony export (immutable) */ __webpack_exports__["__generator"] = __generator;
/* harmony export (immutable) */ __webpack_exports__["__exportStar"] = __exportStar;
/* harmony export (immutable) */ __webpack_exports__["__values"] = __values;
/* harmony export (immutable) */ __webpack_exports__["__read"] = __read;
/* harmony export (immutable) */ __webpack_exports__["__spread"] = __spread;
/* harmony export (immutable) */ __webpack_exports__["__asyncGenerator"] = __asyncGenerator;
/* harmony export (immutable) */ __webpack_exports__["__asyncDelegator"] = __asyncDelegator;
/* harmony export (immutable) */ __webpack_exports__["__asyncValues"] = __asyncValues;
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */
/* global Reflect, Promise */

var extendStatics = Object.setPrototypeOf ||
    ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||
    function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };

function __extends(d, b) {
    extendStatics(d, b);
    function __() { this.constructor = d; }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}

var __assign = Object.assign || function __assign(t) {
    for (var s, i = 1, n = arguments.length; i < n; i++) {
        s = arguments[i];
        for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];
    }
    return t;
};

function __rest(s, e) {
    var t = {};
    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)
        t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function")
        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) if (e.indexOf(p[i]) < 0)
            t[p[i]] = s[p[i]];
    return t;
}

function __decorate(decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
}

function __param(paramIndex, decorator) {
    return function (target, key) { decorator(target, key, paramIndex); }
}

function __metadata(metadataKey, metadataValue) {
    if (typeof Reflect === "object" && typeof Reflect.metadata === "function") return Reflect.metadata(metadataKey, metadataValue);
}

function __awaiter(thisArg, _arguments, P, generator) {
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator.throw(value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}

function __generator(thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (_) try {
            if (f = 1, y && (t = y[op[0] & 2 ? "return" : op[0] ? "throw" : "next"]) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [0, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
}

function __exportStar(m, exports) {
    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];
}

function __values(o) {
    var m = typeof Symbol === "function" && o[Symbol.iterator], i = 0;
    if (m) return m.call(o);
    return {
        next: function () {
            if (o && i >= o.length) o = void 0;
            return { value: o && o[i++], done: !o };
        }
    };
};

function __read(o, n) {
    var m = typeof Symbol === "function" && o[Symbol.iterator];
    if (!m) return o;
    var i = m.call(o), r, ar = [], e;
    try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);
    }
    catch (error) { e = { error: error }; }
    finally {
        try {
            if (r && !r.done && (m = i["return"])) m.call(i);
        }
        finally { if (e) throw e.error; }
    }
    return ar;
};

function __spread() {
    for (var ar = [], i = 0; i < arguments.length; i++)
        ar = ar.concat(__read(arguments[i]));
    return ar;
};

function __asyncGenerator(thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), q = [], c, i;
    return i = { next: verb("next"), "throw": verb("throw"), "return": verb("return") }, i[Symbol.asyncIterator] = function () { return this; }, i;
    function verb(n) { return function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]), next(); }); }; }
    function next() { if (!c && q.length) resume((c = q.shift())[0], c[1]); }
    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(c[3], e); } }
    function step(r) { r.done ? settle(c[2], r) : Promise.resolve(r.value[1]).then(r.value[0] === "yield" ? send : fulfill, reject); }
    function send(value) { settle(c[2], { value: value, done: false }); }
    function fulfill(value) { resume("next", value); }
    function reject(value) { resume("throw", value); }
    function settle(f, v) { c = void 0, f(v), next(); }
};

function __asyncDelegator(o) {
    var i = { next: verb("next"), "throw": verb("throw", function (e) { throw e; }), "return": verb("return", function (v) { return { value: v, done: true }; }) }, p;
    return o = __asyncValues(o), i[Symbol.iterator] = function () { return this; }, i;
    function verb(n, f) { return function (v) { return v = p && n === "throw" ? f(v) : p && v.done ? v : { value: p ? ["yield", v.value] : ["await", (o[n] || f).call(o, v)], done: false }, p = !p, v; }; }
};

function __asyncValues(o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator];
    return m ? m.call(o) : typeof __values === "function" ? __values(o) : o[Symbol.iterator]();
};

/***/ }),
/* 4 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var util = __webpack_require__(0);
var convnet_layers_loss_1 = __webpack_require__(7);
var convnet_layers_dotproducts_1 = __webpack_require__(5);
var convnet_layers_nonlinearities_1 = __webpack_require__(18);
var convnet_layers_pool_1 = __webpack_require__(9);
var convnet_layers_input_1 = __webpack_require__(17);
var convnet_layers_dropout_1 = __webpack_require__(6);
var convnet_layers_normalization_1 = __webpack_require__(8);
var assert = util.assert;
/**
 * Net manages a set of layers
 * For now constraints: Simple linear order of layers, first layer input last layer a cost layer
 */
var Net = (function () {
    function Net(options) {
        if (!options) {
            options = [];
        }
        this.layers = [];
    }
    // takes a list of layer definitions and creates the network layer objects
    Net.prototype.makeLayers = function (defs) {
        // few checks
        assert(defs.length >= 2, 'Error! At least one input layer and one loss layer are required.');
        assert(defs[0].type === 'input', 'Error! First layer must be the input layer, to declare size of inputs');
        // desugar layer_defs for adding activation, dropout layers etc
        var desugar = function (defs) {
            var new_defs = new Array();
            for (var i = 0; i < defs.length; i++) {
                var def = defs[i];
                if (def.type === 'softmax' || def.type === 'svm') {
                    var lossDef = def;
                    // add an fc layer here, there is no reason the user should
                    // have to worry about this and we almost always want to
                    new_defs.push({ type: 'fc', num_neurons: lossDef.num_classes });
                }
                if (def.type === 'regression') {
                    // add an fc layer here, there is no reason the user should
                    // have to worry about this and we almost always want to
                    new_defs.push({ type: 'fc', num_neurons: def.num_neurons });
                }
                if (def.type === 'fc' || def.type === 'conv') {
                    var dotDef = def;
                    if (typeof (dotDef.bias_pref) === 'undefined') {
                        dotDef.bias_pref = 0.0;
                        if (typeof dotDef.activation !== 'undefined' && dotDef.activation === 'relu') {
                            dotDef.bias_pref = 0.1; // relus like a bit of positive bias to get gradients early
                            // otherwise it's technically possible that a relu unit will never turn on (by chance)
                            // and will never get any gradient and never contribute any computation. Dead relu.
                        }
                    }
                }
                new_defs.push(def);
                if (typeof def.activation !== 'undefined') {
                    if (def.activation === 'relu') {
                        new_defs.push({ type: 'relu' });
                    }
                    else if (def.activation === 'sigmoid') {
                        new_defs.push({ type: 'sigmoid' });
                    }
                    else if (def.activation === 'tanh') {
                        new_defs.push({ type: 'tanh' });
                    }
                    else if (def.activation === 'maxout') {
                        // create maxout activation, and pass along group size, if provided
                        var gs = def.group_size !== 'undefined' ? def.group_size : 2;
                        new_defs.push({ type: 'maxout', group_size: gs });
                    }
                    else {
                        console.log('ERROR unsupported activation ' + def.activation);
                    }
                }
                if (typeof def.drop_prob !== 'undefined' && def.type !== 'dropout') {
                    new_defs.push({ type: 'dropout', drop_prob: def.drop_prob });
                }
            }
            return new_defs;
        };
        defs = desugar(defs);
        // create the layers
        this.layers = [];
        for (var i = 0; i < defs.length; i++) {
            var def = defs[i];
            if (i > 0) {
                var prev = this.layers[i - 1];
                def.in_sx = prev.out_sx;
                def.in_sy = prev.out_sy;
                def.in_depth = prev.out_depth;
            }
            switch (def.type) {
                case 'fc':
                    this.layers.push(new convnet_layers_dotproducts_1.FullyConnLayer(def));
                    break;
                case 'lrn':
                    this.layers.push(new convnet_layers_normalization_1.LocalResponseNormalizationLayer(def));
                    break;
                case 'dropout':
                    this.layers.push(new convnet_layers_dropout_1.DropoutLayer(def));
                    break;
                case 'input':
                    this.layers.push(new convnet_layers_input_1.InputLayer(def));
                    break;
                case 'softmax':
                    this.layers.push(new convnet_layers_loss_1.SoftmaxLayer(def));
                    break;
                case 'regression':
                    this.layers.push(new convnet_layers_loss_1.RegressionLayer(def));
                    break;
                case 'conv':
                    this.layers.push(new convnet_layers_dotproducts_1.ConvLayer(def));
                    break;
                case 'pool':
                    this.layers.push(new convnet_layers_pool_1.PoolLayer(def));
                    break;
                case 'relu':
                    this.layers.push(new convnet_layers_nonlinearities_1.ReluLayer(def));
                    break;
                case 'sigmoid':
                    this.layers.push(new convnet_layers_nonlinearities_1.SigmoidLayer(def));
                    break;
                case 'tanh':
                    this.layers.push(new convnet_layers_nonlinearities_1.TanhLayer(def));
                    break;
                case 'maxout':
                    this.layers.push(new convnet_layers_nonlinearities_1.MaxoutLayer(def));
                    break;
                case 'svm':
                    this.layers.push(new convnet_layers_loss_1.SVMLayer(def));
                    break;
                default: console.log('ERROR: UNRECOGNIZED LAYER TYPE: ' + def.type);
            }
        }
    };
    // forward prop the network.
    // The trainer class passes is_training = true, but when this function is
    // called from outside (not from the trainer), it defaults to prediction mode
    Net.prototype.forward = function (V, is_training) {
        if (typeof (is_training) === 'undefined') {
            is_training = false;
        }
        var act = this.layers[0].forward(V, is_training);
        for (var i = 1; i < this.layers.length; i++) {
            act = this.layers[i].forward(act, is_training);
        }
        return act;
    };
    Net.prototype.getCostLoss = function (V, y) {
        this.forward(V, false);
        var N = this.layers.length;
        var loss = this.layers[N - 1].backward(y);
        return loss;
    };
    /**
     * backprop: compute gradients wrt all parameters
     */
    Net.prototype.backward = function (y) {
        var N = this.layers.length;
        var loss = this.layers[N - 1].backward(y); // last layer assumed to be loss layer
        for (var i = N - 2; i >= 0; i--) {
            this.layers[i].backward();
        }
        return loss;
    };
    Net.prototype.getParamsAndGrads = function () {
        // accumulate parameters and gradients for the entire network
        var response = [];
        for (var i = 0; i < this.layers.length; i++) {
            var layer_reponse = this.layers[i].getParamsAndGrads();
            for (var j = 0; j < layer_reponse.length; j++) {
                response.push(layer_reponse[j]);
            }
        }
        return response;
    };
    Net.prototype.getPrediction = function () {
        // this is a convenience function for returning the argmax
        // prediction, assuming the last layer of the net is a softmax
        var S = this.layers[this.layers.length - 1];
        assert(S.layer_type === 'softmax', 'getPrediction function assumes softmax as last layer of the net!');
        if (S instanceof convnet_layers_loss_1.SoftmaxLayer) {
            var p = S.out_act.w;
            var maxv = p[0];
            var maxi = 0;
            for (var i = 1; i < p.length; i++) {
                if (p[i] > maxv) {
                    maxv = p[i];
                    maxi = i;
                }
            }
            return maxi; // return index of the class with highest class probability
        }
        throw Error("to getPrediction, the last layer must be softmax");
    };
    Net.prototype.toJSON = function () {
        var json = {};
        json.layers = [];
        for (var i = 0; i < this.layers.length; i++) {
            json.layers.push(this.layers[i].toJSON());
        }
        return json;
    };
    Net.prototype.fromJSON = function (json) {
        this.layers = [];
        for (var i = 0; i < json.layers.length; i++) {
            var Lj = json.layers[i];
            var t = Lj.layer_type;
            var L = void 0;
            if (t === 'input') {
                L = new convnet_layers_input_1.InputLayer();
            }
            if (t === 'relu') {
                L = new convnet_layers_nonlinearities_1.ReluLayer();
            }
            if (t === 'sigmoid') {
                L = new convnet_layers_nonlinearities_1.SigmoidLayer();
            }
            if (t === 'tanh') {
                L = new convnet_layers_nonlinearities_1.TanhLayer();
            }
            if (t === 'dropout') {
                L = new convnet_layers_dropout_1.DropoutLayer();
            }
            if (t === 'conv') {
                L = new convnet_layers_dotproducts_1.ConvLayer();
            }
            if (t === 'pool') {
                L = new convnet_layers_pool_1.PoolLayer();
            }
            if (t === 'lrn') {
                L = new convnet_layers_normalization_1.LocalResponseNormalizationLayer();
            }
            if (t === 'softmax') {
                L = new convnet_layers_loss_1.SoftmaxLayer();
            }
            if (t === 'regression') {
                L = new convnet_layers_loss_1.RegressionLayer();
            }
            if (t === 'fc') {
                L = new convnet_layers_dotproducts_1.FullyConnLayer();
            }
            if (t === 'maxout') {
                L = new convnet_layers_nonlinearities_1.MaxoutLayer();
            }
            if (t === 'svm') {
                L = new convnet_layers_loss_1.SVMLayer();
            }
            L.fromJSON(Lj);
            this.layers.push(L);
        }
    };
    return Net;
}());
exports.Net = Net;
//# sourceMappingURL=convnet_net.js.map

/***/ }),
/* 5 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var tslib_1 = __webpack_require__(3);
var convnet_vol_1 = __webpack_require__(1);
var layers_1 = __webpack_require__(2);
var util = __webpack_require__(0);
var DotproductsLayer = (function (_super) {
    tslib_1.__extends(DotproductsLayer, _super);
    function DotproductsLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        _this = _super.call(this) || this;
        // optional
        _this.l1_decay_mul = typeof opt.l1_decay_mul !== 'undefined' ? opt.l1_decay_mul : 0.0;
        _this.l2_decay_mul = typeof opt.l2_decay_mul !== 'undefined' ? opt.l2_decay_mul : 1.0;
        return _this;
    }
    return DotproductsLayer;
}(layers_1.LayerBase));
exports.DotproductsLayer = DotproductsLayer;
/**
 * ConvLayer does convolutions (so weight sharing spatially)
*/
var ConvLayer = (function (_super) {
    tslib_1.__extends(ConvLayer, _super);
    function ConvLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var copt = opt;
        _this = _super.call(this, copt) || this;
        // required
        _this.out_depth = copt.filters;
        _this.sx = copt.sx; // filter size. Should be odd if possible, it's cleaner.
        _this.in_depth = copt.in_depth;
        _this.in_sx = copt.in_sx;
        _this.in_sy = copt.in_sy;
        // optional
        _this.sy = typeof copt.sy !== 'undefined' ? copt.sy : _this.sx;
        _this.stride = typeof copt.stride !== 'undefined' ? copt.stride : 1; // stride at which we apply filters to input volume
        _this.pad = typeof copt.pad !== 'undefined' ? copt.pad : 0; // amount of 0 padding to add around borders of input volume
        // computed
        // note we are doing floor, so if the strided convolution of the filter doesnt fit into the input
        // volume exactly, the output volume will be trimmed and not contain the (incomplete) computed
        // final application.
        _this.out_sx = Math.floor((_this.in_sx + _this.pad * 2 - _this.sx) / _this.stride + 1);
        _this.out_sy = Math.floor((_this.in_sy + _this.pad * 2 - _this.sy) / _this.stride + 1);
        _this.layer_type = 'conv';
        // initializations
        _this.filters = [];
        for (var i = 0; i < _this.out_depth; i++) {
            _this.filters.push(new convnet_vol_1.Vol(_this.sx, _this.sy, _this.in_depth));
        }
        var bias = (typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0);
        _this.biases = new convnet_vol_1.Vol(1, 1, _this.out_depth, bias);
        return _this;
    }
    ConvLayer.prototype.forward = function (V) {
        // optimized code by @mdda that achieves 2x speedup over previous version
        this.in_act = V;
        var A = new convnet_vol_1.Vol(this.out_sx | 0, this.out_sy | 0, this.out_depth | 0, 0.0);
        var V_sx = V.sx | 0;
        var V_sy = V.sy | 0;
        var xy_stride = this.stride | 0;
        for (var d = 0; d < this.out_depth; d++) {
            var f = this.filters[d];
            var x = -this.pad | 0;
            var y = -this.pad | 0;
            for (var ay = 0; ay < this.out_sy; y += xy_stride, ay++) {
                x = -this.pad | 0;
                for (var ax = 0; ax < this.out_sx; x += xy_stride, ax++) {
                    // convolve centered at this particular location
                    var a = 0.0;
                    for (var fy = 0; fy < f.sy; fy++) {
                        var oy = y + fy; // coordinates in the original input array coordinates
                        for (var fx = 0; fx < f.sx; fx++) {
                            var ox = x + fx;
                            if (oy >= 0 && oy < V_sy && ox >= 0 && ox < V_sx) {
                                for (var fd = 0; fd < f.depth; fd++) {
                                    // avoid function call overhead (x2) for efficiency, compromise modularity :(
                                    a += f.w[((f.sx * fy) + fx) * f.depth + fd] * V.w[((V_sx * oy) + ox) * V.depth + fd];
                                }
                            }
                        }
                    }
                    a += this.biases.w[d];
                    A.set(ax, ay, d, a);
                }
            }
        }
        this.out_act = A;
        return this.out_act;
    };
    ConvLayer.prototype.backward = function () {
        var V = this.in_act;
        V.dw = util.zeros(V.w.length); // zero out gradient wrt bottom data, we're about to fill it
        var V_sx = V.sx | 0;
        var V_sy = V.sy | 0;
        var xy_stride = this.stride | 0;
        for (var d = 0; d < this.out_depth; d++) {
            var f = this.filters[d];
            var x = -this.pad | 0;
            var y = -this.pad | 0;
            for (var ay = 0; ay < this.out_sy; y += xy_stride, ay++) {
                x = -this.pad | 0;
                for (var ax = 0; ax < this.out_sx; x += xy_stride, ax++) {
                    // convolve centered at this particular location
                    var chain_grad = this.out_act.get_grad(ax, ay, d); // gradient from above, from chain rule
                    for (var fy = 0; fy < f.sy; fy++) {
                        var oy = y + fy; // coordinates in the original input array coordinates
                        for (var fx = 0; fx < f.sx; fx++) {
                            var ox = x + fx;
                            if (oy >= 0 && oy < V_sy && ox >= 0 && ox < V_sx) {
                                for (var fd = 0; fd < f.depth; fd++) {
                                    // avoid function call overhead (x2) for efficiency, compromise modularity :(
                                    var ix1 = ((V_sx * oy) + ox) * V.depth + fd;
                                    var ix2 = ((f.sx * fy) + fx) * f.depth + fd;
                                    f.dw[ix2] += V.w[ix1] * chain_grad;
                                    V.dw[ix1] += f.w[ix2] * chain_grad;
                                }
                            }
                        }
                    }
                    this.biases.dw[d] += chain_grad;
                }
            }
        }
        return 0;
    };
    ConvLayer.prototype.getParamsAndGrads = function () {
        var response = [];
        for (var i = 0; i < this.out_depth; i++) {
            response.push({ params: this.filters[i].w, grads: this.filters[i].dw, l2_decay_mul: this.l2_decay_mul, l1_decay_mul: this.l1_decay_mul });
        }
        response.push({ params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0 });
        return response;
    };
    ConvLayer.prototype.toJSON = function () {
        var json = {};
        json.sx = this.sx; // filter size in x, y dims
        json.sy = this.sy;
        json.stride = this.stride;
        json.in_depth = this.in_depth;
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.l1_decay_mul = this.l1_decay_mul;
        json.l2_decay_mul = this.l2_decay_mul;
        json.pad = this.pad;
        json.filters = [];
        for (var i = 0; i < this.filters.length; i++) {
            json.filters.push(this.filters[i].toJSON());
        }
        json.biases = this.biases.toJSON();
        return json;
    };
    ConvLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.sx = json.sx; // filter size in x, y dims
        this.sy = json.sy;
        this.stride = json.stride;
        this.in_depth = json.in_depth; // depth of input volume
        this.filters = [];
        this.l1_decay_mul = (typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0);
        this.l2_decay_mul = (typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0);
        this.pad = (typeof json.pad !== 'undefined' ? json.pad : 0);
        for (var i = 0; i < json.filters.length; i++) {
            var v = new convnet_vol_1.Vol(0, 0, 0, 0);
            v.fromJSON(json.filters[i]);
            this.filters.push(v);
        }
        this.biases = new convnet_vol_1.Vol(0, 0, 0, 0);
        this.biases.fromJSON(json.biases);
    };
    return ConvLayer;
}(DotproductsLayer));
exports.ConvLayer = ConvLayer;
/**
 * FullyConn is fully connected dot products
 */
var FullyConnLayer = (function (_super) {
    tslib_1.__extends(FullyConnLayer, _super);
    function FullyConnLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var fcopt = opt;
        _this = _super.call(this, fcopt) || this;
        // required
        // ok fine we will allow 'filters' as the word as well
        _this.out_depth = typeof fcopt.num_neurons !== 'undefined' ? fcopt.num_neurons : fcopt.filters;
        // computed
        _this.num_inputs = fcopt.in_sx * fcopt.in_sy * fcopt.in_depth;
        _this.out_sx = 1;
        _this.out_sy = 1;
        _this.layer_type = 'fc';
        // initializations
        _this.filters = [];
        for (var i = 0; i < _this.out_depth; i++) {
            _this.filters.push(new convnet_vol_1.Vol(1, 1, _this.num_inputs));
        }
        var bias = (typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0);
        _this.biases = new convnet_vol_1.Vol(1, 1, _this.out_depth, bias);
        return _this;
    }
    FullyConnLayer.prototype.forward = function (V) {
        this.in_act = V;
        var A = new convnet_vol_1.Vol(1, 1, this.out_depth, 0.0);
        var Vw = V.w;
        for (var i = 0; i < this.out_depth; i++) {
            var a = 0.0;
            var wi = this.filters[i].w;
            for (var d = 0; d < this.num_inputs; d++) {
                a += Vw[d] * wi[d]; // for efficiency use Vols directly for now
            }
            a += this.biases.w[i];
            A.w[i] = a;
        }
        this.out_act = A;
        return this.out_act;
    };
    FullyConnLayer.prototype.backward = function () {
        var V = this.in_act;
        V.dw = util.zeros(V.w.length); // zero out the gradient in input Vol
        // compute gradient wrt weights and data
        for (var i = 0; i < this.out_depth; i++) {
            var tfi = this.filters[i];
            var chain_grad = this.out_act.dw[i];
            for (var d = 0; d < this.num_inputs; d++) {
                V.dw[d] += tfi.w[d] * chain_grad; // grad wrt input data
                tfi.dw[d] += V.w[d] * chain_grad; // grad wrt params
            }
            this.biases.dw[i] += chain_grad;
        }
    };
    FullyConnLayer.prototype.getParamsAndGrads = function () {
        var response = [];
        for (var i = 0; i < this.out_depth; i++) {
            response.push({ params: this.filters[i].w, grads: this.filters[i].dw, l1_decay_mul: this.l1_decay_mul, l2_decay_mul: this.l2_decay_mul });
        }
        response.push({ params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0 });
        return response;
    };
    FullyConnLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.num_inputs = this.num_inputs;
        json.l1_decay_mul = this.l1_decay_mul;
        json.l2_decay_mul = this.l2_decay_mul;
        json.filters = [];
        for (var i = 0; i < this.filters.length; i++) {
            json.filters.push(this.filters[i].toJSON());
        }
        json.biases = this.biases.toJSON();
        return json;
    };
    FullyConnLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.num_inputs = json.num_inputs;
        this.l1_decay_mul = (typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0);
        this.l2_decay_mul = (typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0);
        this.filters = [];
        for (var i = 0; i < json.filters.length; i++) {
            var v = new convnet_vol_1.Vol(0, 0, 0, 0);
            v.fromJSON(json.filters[i]);
            this.filters.push(v);
        }
        this.biases = new convnet_vol_1.Vol(0, 0, 0, 0);
        this.biases.fromJSON(json.biases);
    };
    return FullyConnLayer;
}(DotproductsLayer));
exports.FullyConnLayer = FullyConnLayer;
//# sourceMappingURL=convnet_layers_dotproducts.js.map

/***/ }),
/* 6 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var tslib_1 = __webpack_require__(3);
var layers_1 = __webpack_require__(2);
var util = __webpack_require__(0);
/**
 * An inefficient dropout layer
 * Note this is not most efficient implementation since the layer before
 * computed all these activations and now we're just going to drop them :(
 * same goes for backward pass. Also, if we wanted to be efficient at test time
 * we could equivalently be clever and upscale during train and copy pointers during test
 * todo: make more efficient.
 */
var DropoutLayer = (function (_super) {
    tslib_1.__extends(DropoutLayer, _super);
    function DropoutLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var dopt = opt;
        _this = _super.call(this, dopt) || this;
        // computed
        _this.out_sx = dopt.in_sx;
        _this.out_sy = dopt.in_sy;
        _this.out_depth = dopt.in_depth;
        _this.layer_type = 'dropout';
        _this.drop_prob = typeof dopt.drop_prob !== 'undefined' ? dopt.drop_prob : 0.5;
        var d = util.zeros(_this.out_sx * _this.out_sy * _this.out_depth);
        _this.dropped = d.map(function (v) { return v !== 0; });
        return _this;
    }
    DropoutLayer.prototype.forward = function (V, is_training) {
        this.in_act = V;
        if (typeof (is_training) === 'undefined') {
            is_training = false;
        } // default is prediction mode
        var V2 = V.clone();
        var N = V.w.length;
        if (is_training) {
            // do dropout
            for (var i = 0; i < N; i++) {
                if (Math.random() < this.drop_prob) {
                    V2.w[i] = 0;
                    this.dropped[i] = true;
                } // drop!
                else {
                    this.dropped[i] = false;
                }
            }
        }
        else {
            // scale the activations during prediction
            for (var i = 0; i < N; i++) {
                V2.w[i] *= this.drop_prob;
            }
        }
        this.out_act = V2;
        return this.out_act; // dummy identity function for now
    };
    DropoutLayer.prototype.backward = function () {
        var V = this.in_act; // we need to set dw of this
        var chain_grad = this.out_act;
        var n = V.w.length;
        V.dw = util.zeros(n); // zero out gradient wrt data
        for (var i = 0; i < n; i++) {
            if (!(this.dropped[i])) {
                V.dw[i] = chain_grad.dw[i]; // copy over the gradient
            }
        }
    };
    DropoutLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    DropoutLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.drop_prob = this.drop_prob;
        return json;
    };
    DropoutLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.drop_prob = json.drop_prob;
        var d = util.zeros(this.out_sx * this.out_sy * this.out_depth);
        this.dropped = d.map(function (v) { return v !== 0; });
    };
    return DropoutLayer;
}(layers_1.LayerBase));
exports.DropoutLayer = DropoutLayer;
//# sourceMappingURL=convnet_layers_dropout.js.map

/***/ }),
/* 7 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var tslib_1 = __webpack_require__(3);
var convnet_vol_1 = __webpack_require__(1);
var layers_1 = __webpack_require__(2);
var util = __webpack_require__(0);
/** This is a classifier, with N discrete classes from 0 to N-1
 * it gets a stream of N incoming numbers and computes the softmax
 * function (exponentiate and normalize to sum to 1 as probabilities should)
 */
var SoftmaxLayer = (function (_super) {
    tslib_1.__extends(SoftmaxLayer, _super);
    function SoftmaxLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var lopt = opt;
        _this = _super.call(this, lopt) || this;
        // computed
        _this.num_inputs = lopt.in_sx * lopt.in_sy * lopt.in_depth;
        _this.out_depth = _this.num_inputs;
        _this.out_sx = 1;
        _this.out_sy = 1;
        _this.layer_type = 'softmax';
        return _this;
    }
    SoftmaxLayer.prototype.forward = function (V) {
        this.in_act = V;
        var A = new convnet_vol_1.Vol(1, 1, this.out_depth, 0.0);
        // compute max activation
        var as = V.w;
        var amax = V.w[0];
        for (var i = 1; i < this.out_depth; i++) {
            if (as[i] > amax) {
                amax = as[i];
            }
        }
        // compute exponentials (carefully to not blow up)
        var es = util.zeros(this.out_depth);
        var esum = 0.0;
        for (var i = 0; i < this.out_depth; i++) {
            var e = Math.exp(as[i] - amax);
            esum += e;
            es[i] = e;
        }
        // normalize and output to sum to one
        for (var i = 0; i < this.out_depth; i++) {
            es[i] /= esum;
            A.w[i] = es[i];
        }
        this.es = es; // save these for backprop
        this.out_act = A;
        return this.out_act;
    };
    SoftmaxLayer.prototype.backward = function (y) {
        // compute and accumulate gradient wrt weights and bias of this layer
        var x = this.in_act;
        x.dw = util.zeros(x.w.length); // zero out the gradient of input Vol
        for (var i = 0; i < this.out_depth; i++) {
            var indicator = i === y ? 1.0 : 0.0;
            var mul = -(indicator - this.es[i]);
            x.dw[i] = mul;
        }
        // loss is the class negative log likelihood
        return -Math.log(this.es[y]);
    };
    SoftmaxLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    SoftmaxLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.num_inputs = this.num_inputs;
        return json;
    };
    SoftmaxLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.num_inputs = json.num_inputs;
    };
    return SoftmaxLayer;
}(layers_1.LayerBase));
exports.SoftmaxLayer = SoftmaxLayer;
/**
 * implements an L2 regression cost layer,
 * so penalizes \sum_i(||x_i - y_i||^2), where x is its input
 * and y is the user-provided array of "correct" values.
 */
var RegressionLayer = (function (_super) {
    tslib_1.__extends(RegressionLayer, _super);
    function RegressionLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var lopt = opt;
        _this = _super.call(this, lopt) || this;
        // computed
        _this.num_inputs = lopt.in_sx * lopt.in_sy * lopt.in_depth;
        _this.out_depth = _this.num_inputs;
        _this.out_sx = 1;
        _this.out_sy = 1;
        _this.layer_type = 'regression';
        return _this;
    }
    RegressionLayer.prototype.forward = function (V) {
        this.in_act = V;
        this.out_act = V;
        return V; // identity function
    };
    // y is a list here of size num_inputs
    // or it can be a number if only one value is regressed
    // or it can be a struct {dim: i, val: x} where we only want to
    // regress on dimension i and asking it to have value x
    RegressionLayer.prototype.backward = function (y) {
        // compute and accumulate gradient wrt weights and bias of this layer
        var x = this.in_act;
        x.dw = util.zeros(x.w.length); // zero out the gradient of input Vol
        var loss = 0.0;
        if (y instanceof Array || y instanceof Float64Array) {
            for (var i = 0; i < this.out_depth; i++) {
                var dy = x.w[i] - y[i];
                x.dw[i] = dy;
                loss += 0.5 * dy * dy;
            }
        }
        else if (typeof y === 'number') {
            // lets hope that only one number is being regressed
            var dy = x.w[0] - y;
            x.dw[0] = dy;
            loss += 0.5 * dy * dy;
        }
        else {
            // assume it is a struct with entries .dim and .val
            // and we pass gradient only along dimension dim to be equal to val
            var i = y.dim;
            var yi = y.val;
            var dy = x.w[i] - yi;
            x.dw[i] = dy;
            loss += 0.5 * dy * dy;
        }
        return loss;
    };
    RegressionLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    RegressionLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.num_inputs = this.num_inputs;
        return json;
    };
    RegressionLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.num_inputs = json.num_inputs;
    };
    return RegressionLayer;
}(layers_1.LayerBase));
exports.RegressionLayer = RegressionLayer;
var SVMLayer = (function (_super) {
    tslib_1.__extends(SVMLayer, _super);
    function SVMLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var lopt = opt;
        _this = _super.call(this, lopt) || this;
        // computed
        _this.num_inputs = lopt.in_sx * lopt.in_sy * lopt.in_depth;
        _this.out_depth = _this.num_inputs;
        _this.out_sx = 1;
        _this.out_sy = 1;
        _this.layer_type = 'svm';
        return _this;
    }
    SVMLayer.prototype.forward = function (V) {
        this.in_act = V;
        this.out_act = V; // nothing to do, output raw scores
        return V;
    };
    SVMLayer.prototype.backward = function (y) {
        // compute and accumulate gradient wrt weights and bias of this layer
        var x = this.in_act;
        x.dw = util.zeros(x.w.length); // zero out the gradient of input Vol
        // we're using structured loss here, which means that the score
        // of the ground truth should be higher than the score of any other
        // class, by a margin
        var yscore = x.w[y]; // score of ground truth
        var margin = 1.0;
        var loss = 0.0;
        for (var i = 0; i < this.out_depth; i++) {
            if (y === i) {
                continue;
            }
            var ydiff = -yscore + x.w[i] + margin;
            if (ydiff > 0) {
                // violating dimension, apply loss
                x.dw[i] += 1;
                x.dw[y] -= 1;
                loss += ydiff;
            }
        }
        return loss;
    };
    SVMLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    SVMLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.num_inputs = this.num_inputs;
        return json;
    };
    SVMLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.num_inputs = json.num_inputs;
    };
    return SVMLayer;
}(layers_1.LayerBase));
exports.SVMLayer = SVMLayer;
//# sourceMappingURL=convnet_layers_loss.js.map

/***/ }),
/* 8 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var tslib_1 = __webpack_require__(3);
var layers_1 = __webpack_require__(2);
var util = __webpack_require__(0);
/**
 * a bit experimental layer for now. I think it works but I'm not 100%
 * the gradient check is a bit funky. I'll look into this a bit later.
 * Local Response Normalization in window, along depths of volumes
 */
var LocalResponseNormalizationLayer = (function (_super) {
    tslib_1.__extends(LocalResponseNormalizationLayer, _super);
    function LocalResponseNormalizationLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var lrnopt = opt;
        _this = _super.call(this, lrnopt) || this;
        // required
        _this.k = lrnopt.k;
        _this.n = lrnopt.n;
        _this.alpha = lrnopt.alpha;
        _this.beta = lrnopt.beta;
        // computed
        _this.out_sx = lrnopt.in_sx;
        _this.out_sy = lrnopt.in_sy;
        _this.out_depth = lrnopt.in_depth;
        _this.layer_type = 'lrn';
        // checks
        if (_this.n % 2 === 0) {
            console.log('WARNING n should be odd for LRN layer');
        }
        return _this;
    }
    LocalResponseNormalizationLayer.prototype.forward = function (V) {
        this.in_act = V;
        var A = V.cloneAndZero();
        this.S_cache_ = V.cloneAndZero();
        var n2 = Math.floor(this.n / 2);
        for (var x = 0; x < V.sx; x++) {
            for (var y = 0; y < V.sy; y++) {
                for (var i = 0; i < V.depth; i++) {
                    var ai = V.get(x, y, i);
                    // normalize in a window of size n
                    var den = 0.0;
                    for (var j = Math.max(0, i - n2); j <= Math.min(i + n2, V.depth - 1); j++) {
                        var aa = V.get(x, y, j);
                        den += aa * aa;
                    }
                    den *= this.alpha / this.n;
                    den += this.k;
                    this.S_cache_.set(x, y, i, den); // will be useful for backprop
                    den = Math.pow(den, this.beta);
                    A.set(x, y, i, ai / den);
                }
            }
        }
        this.out_act = A;
        return this.out_act; // dummy identity function for now
    };
    LocalResponseNormalizationLayer.prototype.backward = function () {
        // evaluate gradient wrt data
        var V = this.in_act; // we need to set dw of this
        V.dw = util.zeros(V.w.length); // zero out gradient wrt data
        // let A = this.out_act; // computed in forward pass
        var n2 = Math.floor(this.n / 2);
        for (var x = 0; x < V.sx; x++) {
            for (var y = 0; y < V.sy; y++) {
                for (var i = 0; i < V.depth; i++) {
                    var chain_grad = this.out_act.get_grad(x, y, i);
                    var S = this.S_cache_.get(x, y, i);
                    var SB = Math.pow(S, this.beta);
                    var SB2 = SB * SB;
                    // normalize in a window of size n
                    for (var j = Math.max(0, i - n2); j <= Math.min(i + n2, V.depth - 1); j++) {
                        var aj = V.get(x, y, j);
                        var g = -aj * this.beta * Math.pow(S, this.beta - 1) * this.alpha / this.n * 2 * aj;
                        if (j === i) {
                            g += SB;
                        }
                        g /= SB2;
                        g *= chain_grad;
                        V.add_grad(x, y, j, g);
                    }
                }
            }
        }
    };
    LocalResponseNormalizationLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    LocalResponseNormalizationLayer.prototype.toJSON = function () {
        var json = {};
        json.k = this.k;
        json.n = this.n;
        json.alpha = this.alpha; // normalize by size
        json.beta = this.beta;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.out_depth = this.out_depth;
        json.layer_type = this.layer_type;
        return json;
    };
    LocalResponseNormalizationLayer.prototype.fromJSON = function (json) {
        this.k = json.k;
        this.n = json.n;
        this.alpha = json.alpha; // normalize by size
        this.beta = json.beta;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.out_depth = json.out_depth;
        this.layer_type = json.layer_type;
    };
    return LocalResponseNormalizationLayer;
}(layers_1.LayerBase));
exports.LocalResponseNormalizationLayer = LocalResponseNormalizationLayer;
//# sourceMappingURL=convnet_layers_normalization.js.map

/***/ }),
/* 9 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var tslib_1 = __webpack_require__(3);
var convnet_vol_1 = __webpack_require__(1);
var layers_1 = __webpack_require__(2);
var util = __webpack_require__(0);
var PoolLayer = (function (_super) {
    tslib_1.__extends(PoolLayer, _super);
    function PoolLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var popt = opt;
        _this = _super.call(this, popt) || this;
        // required
        _this.sx = popt.sx; // filter size
        _this.in_depth = popt.in_depth;
        _this.in_sx = popt.in_sx;
        _this.in_sy = popt.in_sy;
        // optional
        _this.sy = typeof popt.sy !== 'undefined' ? popt.sy : _this.sx;
        _this.stride = typeof popt.stride !== 'undefined' ? popt.stride : 2;
        _this.pad = typeof popt.pad !== 'undefined' ? popt.pad : 0; // amount of 0 padding to add around borders of input volume
        // computed
        _this.out_depth = _this.in_depth;
        _this.out_sx = Math.floor((_this.in_sx + _this.pad * 2 - _this.sx) / _this.stride + 1);
        _this.out_sy = Math.floor((_this.in_sy + _this.pad * 2 - _this.sy) / _this.stride + 1);
        _this.layer_type = 'pool';
        // store switches for x,y coordinates for where the max comes from, for each output neuron
        _this.switchx = util.zeros(_this.out_sx * _this.out_sy * _this.out_depth);
        _this.switchy = util.zeros(_this.out_sx * _this.out_sy * _this.out_depth);
        return _this;
    }
    PoolLayer.prototype.forward = function (V) {
        this.in_act = V;
        var A = new convnet_vol_1.Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);
        var n = 0; // a counter for switches
        for (var d = 0; d < this.out_depth; d++) {
            var x = -this.pad;
            var y = -this.pad;
            for (var ax = 0; ax < this.out_sx; x += this.stride, ax++) {
                y = -this.pad;
                for (var ay = 0; ay < this.out_sy; y += this.stride, ay++) {
                    // convolve centered at this particular location
                    var a = -99999; // hopefully small enough ;\
                    var winx = -1, winy = -1;
                    for (var fx = 0; fx < this.sx; fx++) {
                        for (var fy = 0; fy < this.sy; fy++) {
                            var oy = y + fy;
                            var ox = x + fx;
                            if (oy >= 0 && oy < V.sy && ox >= 0 && ox < V.sx) {
                                var v = V.get(ox, oy, d);
                                // perform max pooling and store pointers to where
                                // the max came from. This will speed up backprop
                                // and can help make nice visualizations in future
                                if (v > a) {
                                    a = v;
                                    winx = ox;
                                    winy = oy;
                                }
                            }
                        }
                    }
                    this.switchx[n] = winx;
                    this.switchy[n] = winy;
                    n++;
                    A.set(ax, ay, d, a);
                }
            }
        }
        this.out_act = A;
        return this.out_act;
    };
    PoolLayer.prototype.backward = function () {
        // pooling layers have no parameters, so simply compute
        // gradient wrt data here
        var V = this.in_act;
        V.dw = util.zeros(V.w.length); // zero out gradient wrt data
        // const A = this.out_act; // computed in forward pass
        var n = 0;
        for (var d = 0; d < this.out_depth; d++) {
            var x = -this.pad;
            var y = -this.pad;
            for (var ax = 0; ax < this.out_sx; x += this.stride, ax++) {
                y = -this.pad;
                for (var ay = 0; ay < this.out_sy; y += this.stride, ay++) {
                    var chain_grad = this.out_act.get_grad(ax, ay, d);
                    V.add_grad(this.switchx[n], this.switchy[n], d, chain_grad);
                    n++;
                }
            }
        }
    };
    PoolLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    PoolLayer.prototype.toJSON = function () {
        var json = {};
        json.sx = this.sx;
        json.sy = this.sy;
        json.stride = this.stride;
        json.in_depth = this.in_depth;
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.pad = this.pad;
        return json;
    };
    PoolLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.sx = json.sx;
        this.sy = json.sy;
        this.stride = json.stride;
        this.in_depth = json.in_depth;
        this.pad = (typeof json.pad !== 'undefined' ? json.pad : 0); // backwards compatibility
        this.switchx = util.zeros(this.out_sx * this.out_sy * this.out_depth); // need to re-init these appropriately
        this.switchy = util.zeros(this.out_sx * this.out_sy * this.out_depth);
    };
    return PoolLayer;
}(layers_1.LayerBase));
exports.PoolLayer = PoolLayer;
//# sourceMappingURL=convnet_layers_pool.js.map

/***/ }),
/* 10 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var util = __webpack_require__(0);
var Trainer = (function () {
    function Trainer(net, options) {
        this.net = net;
        if (!options) {
            options = {};
        }
        this.learning_rate = typeof options.learning_rate !== 'undefined' ? options.learning_rate : 0.01;
        this.l1_decay = typeof options.l1_decay !== 'undefined' ? options.l1_decay : 0.0;
        this.l2_decay = typeof options.l2_decay !== 'undefined' ? options.l2_decay : 0.0;
        this.batch_size = typeof options.batch_size !== 'undefined' ? options.batch_size : 1;
        this.method = typeof options.method !== 'undefined' ? options.method : 'sgd'; // sgd/adam/adagrad/adadelta/windowgrad/netsterov
        this.momentum = typeof options.momentum !== 'undefined' ? options.momentum : 0.9;
        this.ro = typeof options.ro !== 'undefined' ? options.ro : 0.95; // used in adadelta
        this.eps = typeof options.eps !== 'undefined' ? options.eps : 1e-8; // used in adam or adadelta
        this.beta1 = typeof options.beta1 !== 'undefined' ? options.beta1 : 0.9; // used in adam
        this.beta2 = typeof options.beta2 !== 'undefined' ? options.beta2 : 0.999; // used in adam
        this.k = 0; // iteration counter
        this.gsum = []; // last iteration gradients (used for momentum calculations)
        this.xsum = []; // used in adam or adadelta
        // check if regression is expected
        if (this.net.layers[this.net.layers.length - 1].layer_type === "regression") {
            this.regression = true;
        }
        else {
            this.regression = false;
        }
    }
    Trainer.prototype.train = function (x, y) {
        var start = new Date().getTime();
        this.net.forward(x, true); // also set the flag that lets the net know we're just training
        var end = new Date().getTime();
        var fwd_time = end - start;
        start = new Date().getTime();
        var cost_loss = this.net.backward(y);
        var l2_decay_loss = 0.0;
        var l1_decay_loss = 0.0;
        end = new Date().getTime();
        var bwd_time = end - start;
        if (this.regression && y.constructor !== Array) {
            // console.log("Warning: a regression net requires an array as training output vector.");
        }
        this.k++;
        if (this.k % this.batch_size === 0) {
            var pglist = this.net.getParamsAndGrads();
            // initialize lists for accumulators. Will only be done once on first iteration
            if (this.gsum.length === 0 && (this.method !== 'sgd' || this.momentum > 0.0)) {
                // only vanilla sgd doesnt need either lists
                // momentum needs gsum
                // adagrad needs gsum
                // adam and adadelta needs gsum and xsum
                for (var i = 0; i < pglist.length; i++) {
                    this.gsum.push(util.zeros(pglist[i].params.length));
                    if (this.method === 'adam' || this.method === 'adadelta') {
                        this.xsum.push(util.zeros(pglist[i].params.length));
                    }
                    else {
                        this.xsum.push([]); // conserve memory
                    }
                }
            }
            // perform an update for all sets of weights
            for (var i = 0; i < pglist.length; i++) {
                var pg = pglist[i]; // param, gradient, other options in future (custom learning rate etc)
                var p = pg.params;
                var g = pg.grads;
                // learning rate for some parameters.
                var l2_decay_mul = typeof pg.l2_decay_mul !== 'undefined' ? pg.l2_decay_mul : 1.0;
                var l1_decay_mul = typeof pg.l1_decay_mul !== 'undefined' ? pg.l1_decay_mul : 1.0;
                var l2_decay = this.l2_decay * l2_decay_mul;
                var l1_decay = this.l1_decay * l1_decay_mul;
                var plen = p.length;
                for (var j = 0; j < plen; j++) {
                    l2_decay_loss += l2_decay * p[j] * p[j] / 2; // accumulate weight decay loss
                    l1_decay_loss += l1_decay * Math.abs(p[j]);
                    var l1grad = l1_decay * (p[j] > 0 ? 1 : -1);
                    var l2grad = l2_decay * (p[j]);
                    var gij = (l2grad + l1grad + g[j]) / this.batch_size; // raw batch gradient
                    var gsumi = this.gsum[i];
                    var xsumi = this.xsum[i];
                    if (this.method === 'adam') {
                        // adam update
                        gsumi[j] = gsumi[j] * this.beta1 + (1 - this.beta1) * gij; // update biased first moment estimate
                        xsumi[j] = xsumi[j] * this.beta2 + (1 - this.beta2) * gij * gij; // update biased second moment estimate
                        var biasCorr1 = gsumi[j] * (1 - Math.pow(this.beta1, this.k)); // correct bias first moment estimate
                        var biasCorr2 = xsumi[j] * (1 - Math.pow(this.beta2, this.k)); // correct bias second moment estimate
                        var dx = -this.learning_rate * biasCorr1 / (Math.sqrt(biasCorr2) + this.eps);
                        p[j] += dx;
                    }
                    else if (this.method === 'adagrad') {
                        // adagrad update
                        gsumi[j] = gsumi[j] + gij * gij;
                        var dx = -this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij;
                        p[j] += dx;
                    }
                    else if (this.method === 'windowgrad') {
                        // this is adagrad but with a moving window weighted average
                        // so the gradient is not accumulated over the entire history of the run.
                        // it's also referred to as Idea #1 in Zeiler paper on Adadelta. Seems reasonable to me!
                        gsumi[j] = this.ro * gsumi[j] + (1 - this.ro) * gij * gij;
                        var dx = -this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij; // eps added for better conditioning
                        p[j] += dx;
                    }
                    else if (this.method === 'adadelta') {
                        gsumi[j] = this.ro * gsumi[j] + (1 - this.ro) * gij * gij;
                        var dx = -Math.sqrt((xsumi[j] + this.eps) / (gsumi[j] + this.eps)) * gij;
                        xsumi[j] = this.ro * xsumi[j] + (1 - this.ro) * dx * dx; // yes, xsum lags behind gsum by 1.
                        p[j] += dx;
                    }
                    else if (this.method === 'nesterov') {
                        var dx = gsumi[j];
                        gsumi[j] = gsumi[j] * this.momentum + this.learning_rate * gij;
                        dx = this.momentum * dx - (1.0 + this.momentum) * gsumi[j];
                        p[j] += dx;
                    }
                    else {
                        // assume SGD
                        if (this.momentum > 0.0) {
                            // momentum update
                            var dx = this.momentum * gsumi[j] - this.learning_rate * gij; // step
                            gsumi[j] = dx; // back this up for next iteration of momentum
                            p[j] += dx; // apply corrected gradient
                        }
                        else {
                            // vanilla sgd
                            p[j] += -this.learning_rate * gij;
                        }
                    }
                    g[j] = 0.0; // zero out gradient so that we can begin accumulating anew
                }
            }
        }
        // appending softmax_loss for backwards compatibility, but from now on we will always use cost_loss
        // in future, TODO: have to completely redo the way loss is done around the network as currently
        // loss is a bit of a hack. Ideally, user should specify arbitrary number of loss functions on any layer
        // and it should all be computed correctly and automatically.
        return {
            fwd_time: fwd_time, bwd_time: bwd_time,
            l2_decay_loss: l2_decay_loss, l1_decay_loss: l1_decay_loss,
            cost_loss: cost_loss, softmax_loss: cost_loss,
            loss: cost_loss + l1_decay_loss + l2_decay_loss
        };
    };
    return Trainer;
}());
exports.Trainer = Trainer;
//# sourceMappingURL=convnet_trainers.js.map

/***/ }),
/* 11 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
// direct export
var convnet_vol_1 = __webpack_require__(1);
exports.Vol = convnet_vol_1.Vol;
var convnet_net_1 = __webpack_require__(4);
exports.Net = convnet_net_1.Net;
var convnet_magicnet_1 = __webpack_require__(14);
exports.MagicNet = convnet_magicnet_1.MagicNet;
var convnet_util_1 = __webpack_require__(0);
exports.randf = convnet_util_1.randf;
exports.randi = convnet_util_1.randi;
exports.randn = convnet_util_1.randn;
exports.randperm = convnet_util_1.randperm;
var convnet_layers_dotproducts_1 = __webpack_require__(5);
exports.ConvLayer = convnet_layers_dotproducts_1.ConvLayer;
exports.FullyConnLayer = convnet_layers_dotproducts_1.FullyConnLayer;
var convnet_layers_dropout_1 = __webpack_require__(6);
exports.DropoutLayer = convnet_layers_dropout_1.DropoutLayer;
var convnet_layers_loss_1 = __webpack_require__(7);
exports.RegressionLayer = convnet_layers_loss_1.RegressionLayer;
exports.SVMLayer = convnet_layers_loss_1.SVMLayer;
exports.SoftmaxLayer = convnet_layers_loss_1.SoftmaxLayer;
var convnet_layers_normalization_1 = __webpack_require__(8);
exports.LocalResponseNormalizationLayer = convnet_layers_normalization_1.LocalResponseNormalizationLayer;
var convnet_layers_pool_1 = __webpack_require__(9);
exports.PoolLayer = convnet_layers_pool_1.PoolLayer;
// module export
var cnnvis = __webpack_require__(13);
exports.cnnvis = cnnvis;
var cnnutil = __webpack_require__(12);
exports.cnnutil = cnnutil;
var util = __webpack_require__(0);
exports.util = util;
var volutil = __webpack_require__(15);
exports.volutil = volutil;
var deepqlearn = __webpack_require__(16);
exports.deepqlearn = deepqlearn;
// rename
var convnet_trainers_1 = __webpack_require__(10);
exports.Trainer = convnet_trainers_1.Trainer;
exports.SGDTrainer = convnet_trainers_1.Trainer;
//# sourceMappingURL=index.js.map

/***/ }),
/* 12 */
/***/ (function(module, exports) {

// contains various utility functions
Object.defineProperty(exports, "__esModule", { value: true });
/**
 * a window stores _size_ number of values
 * and returns averages. Useful for keeping running
 * track of validation or training accuracy during SGD
 */
var Window = (function () {
    function Window(size, minsize) {
        this.v = [];
        this.size = typeof (size) === 'undefined' ? 100 : size;
        this.minsize = typeof (minsize) === 'undefined' ? 20 : minsize;
        this.sum = 0;
    }
    Window.prototype.add = function (x) {
        this.v.push(x);
        this.sum += x;
        if (this.v.length > this.size) {
            var xold = this.v.shift();
            this.sum -= xold;
        }
    };
    Window.prototype.get_average = function () {
        if (this.v.length < this.minsize) {
            return -1;
        }
        else {
            return this.sum / this.v.length;
        }
    };
    Window.prototype.reset = function () {
        this.v = [];
        this.sum = 0;
    };
    return Window;
}());
exports.Window = Window;
/**
 * returns min, max and indeces of an array
 */
function maxmin(w) {
    if (w.length === 0) {
        return {};
    } // ... ;s
    var maxv = w[0];
    var minv = w[0];
    var maxi = 0;
    var mini = 0;
    for (var i = 1; i < w.length; i++) {
        if (w[i] > maxv) {
            maxv = w[i];
            maxi = i;
        }
        if (w[i] < minv) {
            minv = w[i];
            mini = i;
        }
    }
    return { maxi: maxi, maxv: maxv, mini: mini, minv: minv, dv: maxv - minv };
}
exports.maxmin = maxmin;
/**
 * returns string representation of float
 * but truncated to length of d digits
 */
function f2t(x, d) {
    if (typeof (d) === 'undefined') {
        d = 5;
    }
    var dd = 1.0 * Math.pow(10, d);
    return '' + Math.floor(x * dd) / dd;
}
exports.f2t = f2t;
//# sourceMappingURL=cnnutil.js.map

/***/ }),
/* 13 */
/***/ (function(module, exports) {

// contains various utility functions
Object.defineProperty(exports, "__esModule", { value: true });
// can be used to graph loss, or accuract over time
var Graph = (function () {
    function Graph(options) {
        if (!options) {
            options = {};
        }
        this.step_horizon = options.step_horizon || 1000;
        this.pts = [];
        this.maxy = -9999;
        this.miny = 9999;
    }
    /**
     * canv is the canvas we wish to update with this new datapoint
     */
    Graph.prototype.add = function (step, y) {
        var time = new Date().getTime(); // in ms
        if (y > this.maxy * 0.99) {
            this.maxy = y * 1.05;
        }
        if (y < this.miny * 1.01) {
            this.miny = y * 0.95;
        }
        this.pts.push({ step: step, time: time, y: y });
        if (step > this.step_horizon) {
            this.step_horizon *= 2;
        }
    };
    // elt is a canvas we wish to draw into
    Graph.prototype.drawSelf = function (canv) {
        var pad = 25;
        var H = canv.height;
        var W = canv.width;
        var ctx = canv.getContext('2d');
        ctx.clearRect(0, 0, W, H);
        ctx.font = "10px Georgia";
        var f2t = function (x) {
            var dd = 1.0 * Math.pow(10, 2);
            return '' + Math.floor(x * dd) / dd;
        };
        // draw guidelines and values
        ctx.strokeStyle = "#999";
        ctx.beginPath();
        var ng = 10;
        for (var i = 0; i <= ng; i++) {
            var xpos = i / ng * (W - 2 * pad) + pad;
            ctx.moveTo(xpos, pad);
            ctx.lineTo(xpos, H - pad);
            ctx.fillText(f2t(i / ng * this.step_horizon / 1000) + 'k', xpos, H - pad + 14);
        }
        for (var i = 0; i <= ng; i++) {
            var ypos = i / ng * (H - 2 * pad) + pad;
            ctx.moveTo(pad, ypos);
            ctx.lineTo(W - pad, ypos);
            ctx.fillText(f2t((ng - i) / ng * (this.maxy - this.miny) + this.miny), 0, ypos);
        }
        ctx.stroke();
        var N = this.pts.length;
        if (N < 2) {
            return;
        }
        // draw the actual curve
        var t = function (x, y, s) {
            var tx = x / s.step_horizon * (W - pad * 2) + pad;
            var ty = H - ((y - s.miny) / (s.maxy - s.miny) * (H - pad * 2) + pad);
            return { tx: tx, ty: ty };
        };
        ctx.strokeStyle = "red";
        ctx.beginPath();
        for (var i = 0; i < N; i++) {
            // draw line from i-1 to i
            var p = this.pts[i];
            var pt = t(p.step, p.y, this);
            if (i === 0) {
                ctx.moveTo(pt.tx, pt.ty);
            }
            else {
                ctx.lineTo(pt.tx, pt.ty);
            }
        }
        ctx.stroke();
    };
    return Graph;
}());
exports.Graph = Graph;
// same as graph but draws multiple lines. For now I'm lazy and duplicating
// the code, but in future I will merge these two more nicely.
var MultiGraph = (function () {
    function MultiGraph(legend, options) {
        if (!options) {
            options = {};
        }
        this.step_horizon = options.step_horizon || 1000;
        if (typeof options.maxy !== 'undefined') {
            this.maxy_forced = options.maxy;
        }
        if (typeof options.miny !== 'undefined') {
            this.miny_forced = options.miny;
        }
        this.pts = [];
        this.maxy = -9999;
        this.miny = 9999;
        this.numlines = 0;
        this.numlines = legend.length;
        this.legend = legend;
        this.styles = ["red", "blue", "green", "black", "magenta", "cyan", "purple", "aqua", "olive", "lime", "navy"];
        // 17 basic colors: aqua, black, blue, fuchsia, gray, green, lime, maroon, navy, olive, orange, purple, red, silver, teal, white, and yellow
    }
    // canv is the canvas we wish to update with this new datapoint
    MultiGraph.prototype.add = function (step, yl) {
        var time = new Date().getTime(); // in ms
        var n = yl.length;
        for (var k = 0; k < n; k++) {
            var y = yl[k];
            if (y > this.maxy * 0.99) {
                this.maxy = y * 1.05;
            }
            ;
            if (y < this.miny * 1.01) {
                this.miny = y * 0.95;
            }
            ;
        }
        if (typeof this.maxy_forced !== 'undefined') {
            this.maxy = this.maxy_forced;
        }
        ;
        if (typeof this.miny_forced !== 'undefined') {
            this.miny = this.miny_forced;
        }
        ;
        this.pts.push({ step: step, time: time, yl: yl });
        if (step > this.step_horizon) {
            this.step_horizon *= 2;
        }
        ;
    };
    // elt is a canvas we wish to draw into
    MultiGraph.prototype.drawSelf = function (canv) {
        var pad = 25;
        var H = canv.height;
        var W = canv.width;
        var ctx = canv.getContext('2d');
        ctx.clearRect(0, 0, W, H);
        ctx.font = "10px Georgia";
        var f2t = function (x) {
            var dd = 1.0 * Math.pow(10, 2);
            return '' + Math.floor(x * dd) / dd;
        };
        // draw guidelines and values
        ctx.strokeStyle = "#999";
        ctx.beginPath();
        var ng = 10;
        for (var i = 0; i <= ng; i++) {
            var xpos = i / ng * (W - 2 * pad) + pad;
            ctx.moveTo(xpos, pad);
            ctx.lineTo(xpos, H - pad);
            ctx.fillText(f2t(i / ng * this.step_horizon / 1000) + 'k', xpos, H - pad + 14);
        }
        for (var i = 0; i <= ng; i++) {
            var ypos = i / ng * (H - 2 * pad) + pad;
            ctx.moveTo(pad, ypos);
            ctx.lineTo(W - pad, ypos);
            ctx.fillText(f2t((ng - i) / ng * (this.maxy - this.miny) + this.miny), 0, ypos);
        }
        ctx.stroke();
        var N = this.pts.length;
        if (N < 2) {
            return;
        }
        // draw legend
        for (var k = 0; k < this.numlines; k++) {
            ctx.fillStyle = this.styles[k % this.styles.length];
            ctx.fillText(this.legend[k], W - pad - 100, pad + 20 + k * 16);
        }
        ctx.fillStyle = "black";
        // draw the actual curve
        var t = function (x, y, s) {
            var tx = x / s.step_horizon * (W - pad * 2) + pad;
            var ty = H - ((y - s.miny) / (s.maxy - s.miny) * (H - pad * 2) + pad);
            return { tx: tx, ty: ty };
        };
        for (var k = 0; k < this.numlines; k++) {
            ctx.strokeStyle = this.styles[k % this.styles.length];
            ctx.beginPath();
            for (var i = 0; i < N; i++) {
                // draw line from i-1 to i
                var p = this.pts[i];
                var pt = t(p.step, p.yl[k], this);
                if (i === 0) {
                    ctx.moveTo(pt.tx, pt.ty);
                }
                else {
                    ctx.lineTo(pt.tx, pt.ty);
                }
            }
            ctx.stroke();
        }
    };
    return MultiGraph;
}());
exports.MultiGraph = MultiGraph;
//# sourceMappingURL=cnnvis.js.map

/***/ }),
/* 14 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var util = __webpack_require__(0);
var convnet_net_1 = __webpack_require__(4);
var convnet_trainers_1 = __webpack_require__(10);
// used utilities, make explicit local references
var randf = util.randf;
var randi = util.randi;
var maxmin = util.maxmin;
var randperm = util.randperm;
var weightedSample = util.weightedSample;
var getopt = util.getopt;
var arrUnique = util.arrUnique;
/*
A MagicNet takes data: a list of convnetjs.Vol(), and labels
which for now are assumed to be class indeces 0..K. MagicNet then:
- creates data folds for cross-validation
- samples candidate networks
- evaluates candidate networks on all data folds
- produces predictions by model-averaging the best networks
*/
var MagicNet = (function () {
    function MagicNet(data, labels, opt) {
        if (!opt) {
            opt = {};
        }
        if (typeof data === 'undefined') {
            data = [];
        }
        if (typeof labels === 'undefined') {
            labels = [];
        }
        // required inputs
        this.data = data; // store these pointers to data
        this.labels = labels;
        // optional inputs
        this.train_ratio = getopt(opt, 'train_ratio', 0.7);
        this.num_folds = getopt(opt, 'num_folds', 10);
        this.num_candidates = getopt(opt, 'num_candidates', 50); // we evaluate several in parallel
        // how many epochs of data to train every network? for every fold?
        // higher values mean higher accuracy in final results, but more expensive
        this.num_epochs = getopt(opt, 'num_epochs', 50);
        // number of best models to average during prediction. Usually higher = better
        this.ensemble_size = getopt(opt, 'ensemble_size', 10);
        // candidate parameters
        this.batch_size_min = getopt(opt, 'batch_size_min', 10);
        this.batch_size_max = getopt(opt, 'batch_size_max', 300);
        this.l2_decay_min = getopt(opt, 'l2_decay_min', -4);
        this.l2_decay_max = getopt(opt, 'l2_decay_max', 2);
        this.learning_rate_min = getopt(opt, 'learning_rate_min', -4);
        this.learning_rate_max = getopt(opt, 'learning_rate_max', 0);
        this.momentum_min = getopt(opt, 'momentum_min', 0.9);
        this.momentum_max = getopt(opt, 'momentum_max', 0.9);
        this.neurons_min = getopt(opt, 'neurons_min', 5);
        this.neurons_max = getopt(opt, 'neurons_max', 30);
        // computed
        this.folds = []; // data fold indices, gets filled by sampleFolds()
        this.candidates = []; // candidate networks that are being currently evaluated
        this.evaluated_candidates = []; // history of all candidates that were fully evaluated on all folds
        this.unique_labels = arrUnique(labels);
        this.iter = 0; // iteration counter, goes from 0 -> num_epochs * num_training_data
        this.foldix = 0; // index of active fold
        // callbacks
        this.finish_fold_callback = null;
        this.finish_batch_callback = null;
        // initializations
        if (this.data.length > 0) {
            this.sampleFolds();
            this.sampleCandidates();
        }
    }
    ;
    // sets this.folds to a sampling of this.num_folds folds
    MagicNet.prototype.sampleFolds = function () {
        var N = this.data.length;
        var num_train = Math.floor(this.train_ratio * N);
        this.folds = []; // flush folds, if any
        for (var i = 0; i < this.num_folds; i++) {
            var p = randperm(N);
            this.folds.push({ train_ix: p.slice(0, num_train), test_ix: p.slice(num_train, N) });
        }
    };
    // returns a random candidate network
    MagicNet.prototype.sampleCandidate = function () {
        var input_depth = this.data[0].w.length;
        var num_classes = this.unique_labels.length;
        // sample network topology and hyperparameters
        var layer_defs = [];
        layer_defs.push({ type: 'input', out_sx: 1, out_sy: 1, out_depth: input_depth });
        var nl = weightedSample([0, 1, 2, 3], [0.2, 0.3, 0.3, 0.2]); // prefer nets with 1,2 hidden layers
        for (var q = 0; q < nl; q++) {
            var ni = randi(this.neurons_min, this.neurons_max);
            var act = ['tanh', 'maxout', 'relu'][randi(0, 3)];
            if (randf(0, 1) < 0.5) {
                var dp = Math.random();
                layer_defs.push({ type: 'fc', num_neurons: ni, activation: act, drop_prob: dp });
            }
            else {
                layer_defs.push({ type: 'fc', num_neurons: ni, activation: act });
            }
        }
        layer_defs.push({ type: 'softmax', num_classes: num_classes });
        var net = new convnet_net_1.Net();
        net.makeLayers(layer_defs);
        // sample training hyperparameters
        var bs = randi(this.batch_size_min, this.batch_size_max); // batch size
        var l2 = Math.pow(10, randf(this.l2_decay_min, this.l2_decay_max)); // l2 weight decay
        var lr = Math.pow(10, randf(this.learning_rate_min, this.learning_rate_max)); // learning rate
        var mom = randf(this.momentum_min, this.momentum_max); // momentum. Lets just use 0.9, works okay usually ;p
        var tp = randf(0, 1); // trainer type
        var trainer_def;
        if (tp < 0.33) {
            trainer_def = { method: 'adadelta', batch_size: bs, l2_decay: l2 };
        }
        else if (tp < 0.66) {
            trainer_def = { method: 'adagrad', learning_rate: lr, batch_size: bs, l2_decay: l2 };
        }
        else {
            trainer_def = { method: 'sgd', learning_rate: lr, momentum: mom, batch_size: bs, l2_decay: l2 };
        }
        var trainer = new convnet_trainers_1.Trainer(net, trainer_def);
        var cand = {};
        cand.acc = [];
        cand.accv = 0; // this will maintained as sum(acc) for convenience
        cand.layer_defs = layer_defs;
        cand.trainer_def = trainer_def;
        cand.net = net;
        cand.trainer = trainer;
        return cand;
    };
    // sets this.candidates with this.num_candidates candidate nets
    MagicNet.prototype.sampleCandidates = function () {
        this.candidates = []; // flush, if any
        for (var i = 0; i < this.num_candidates; i++) {
            var cand = this.sampleCandidate();
            this.candidates.push(cand);
        }
    };
    MagicNet.prototype.step = function () {
        // run an example through current candidate
        this.iter++;
        // step all candidates on a random data point
        var fold = this.folds[this.foldix]; // active fold
        var dataix = fold.train_ix[randi(0, fold.train_ix.length)];
        for (var k = 0; k < this.candidates.length; k++) {
            var x = this.data[dataix];
            var l = this.labels[dataix];
            this.candidates[k].trainer.train(x, l);
        }
        // process consequences: sample new folds, or candidates
        var lastiter = this.num_epochs * fold.train_ix.length;
        if (this.iter >= lastiter) {
            // finished evaluation of this fold. Get final validation
            // accuracies, record them, and go on to next fold.
            var val_acc = this.evalValErrors();
            for (var k = 0; k < this.candidates.length; k++) {
                var c = this.candidates[k];
                c.acc.push(val_acc[k]);
                c.accv += val_acc[k];
            }
            this.iter = 0; // reset step number
            this.foldix++; // increment fold
            if (this.finish_fold_callback !== null) {
                this.finish_fold_callback();
            }
            if (this.foldix >= this.folds.length) {
                // we finished all folds as well! Record these candidates
                // and sample new ones to evaluate.
                for (var k = 0; k < this.candidates.length; k++) {
                    this.evaluated_candidates.push(this.candidates[k]);
                }
                // sort evaluated candidates according to accuracy achieved
                this.evaluated_candidates.sort(function (a, b) {
                    return (a.accv / a.acc.length)
                        > (b.accv / b.acc.length)
                        ? -1 : 1;
                });
                // and clip only to the top few ones (lets place limit at 3*ensemble_size)
                // otherwise there are concerns with keeping these all in memory
                // if MagicNet is being evaluated for a very long time
                if (this.evaluated_candidates.length > 3 * this.ensemble_size) {
                    this.evaluated_candidates = this.evaluated_candidates.slice(0, 3 * this.ensemble_size);
                }
                if (this.finish_batch_callback !== null) {
                    this.finish_batch_callback();
                }
                this.sampleCandidates(); // begin with new candidates
                this.foldix = 0; // reset this
            }
            else {
                // we will go on to another fold. reset all candidates nets
                for (var k = 0; k < this.candidates.length; k++) {
                    var c = this.candidates[k];
                    var net = new convnet_net_1.Net();
                    net.makeLayers(c.layer_defs);
                    var trainer = new convnet_trainers_1.Trainer(net, c.trainer_def);
                    c.net = net;
                    c.trainer = trainer;
                }
            }
        }
    };
    MagicNet.prototype.evalValErrors = function () {
        // evaluate candidates on validation data and return performance of current networks
        // as simple list
        var vals = [];
        var fold = this.folds[this.foldix]; // active fold
        for (var k = 0; k < this.candidates.length; k++) {
            var net = this.candidates[k].net;
            var v = 0.0;
            for (var q = 0; q < fold.test_ix.length; q++) {
                var x = this.data[fold.test_ix[q]];
                var l = this.labels[fold.test_ix[q]];
                net.forward(x);
                var yhat = net.getPrediction();
                v += (yhat === l ? 1.0 : 0.0); // 0 1 loss
            }
            v /= fold.test_ix.length; // normalize
            vals.push(v);
        }
        return vals;
    };
    /**
     * returns prediction scores for given test data point, as Vol
     * uses an averaged prediction from the best ensemble_size models
     * x is a Vol.
     */
    MagicNet.prototype.predict_soft = function (data) {
        // forward prop the best networks
        // and accumulate probabilities at last layer into a an output Vol
        var eval_candidates = [];
        var nv = 0;
        if (this.evaluated_candidates.length === 0) {
            // not sure what to do here, first batch of nets hasnt evaluated yet
            // lets just predict with current candidates.
            nv = this.candidates.length;
            eval_candidates = this.candidates;
        }
        else {
            // forward prop the best networks from evaluated_candidates
            nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);
            eval_candidates = this.evaluated_candidates;
        }
        // forward nets of all candidates and average the predictions
        var xout, n;
        for (var j = 0; j < nv; j++) {
            var net = eval_candidates[j].net;
            var x = net.forward(data);
            if (j === 0) {
                xout = x;
                n = x.w.length;
            }
            else {
                // add it on
                for (var d = 0; d < n; d++) {
                    xout.w[d] += x.w[d];
                }
            }
        }
        // produce average
        for (var d = 0; d < n; d++) {
            xout.w[d] /= nv;
        }
        return xout;
    };
    MagicNet.prototype.predict = function (data) {
        var xout = this.predict_soft(data);
        var predicted_label;
        if (xout.w.length !== 0) {
            var stats = maxmin(xout.w);
            predicted_label = stats.maxi;
        }
        else {
            predicted_label = -1; // error out
        }
        return predicted_label;
    };
    MagicNet.prototype.toJSON = function () {
        // dump the top ensemble_size networks as a list
        var nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);
        var json = {};
        json.nets = [];
        for (var i = 0; i < nv; i++) {
            json.nets.push(this.evaluated_candidates[i].net.toJSON());
        }
        return json;
    };
    MagicNet.prototype.fromJSON = function (json) {
        this.ensemble_size = json.nets.length;
        this.evaluated_candidates = [];
        for (var i = 0; i < this.ensemble_size; i++) {
            var net = new convnet_net_1.Net();
            net.fromJSON(json.nets[i]);
            var dummy_candidate = {};
            dummy_candidate.net = net;
            this.evaluated_candidates.push(dummy_candidate);
        }
    };
    // callback functions
    // called when a fold is finished, while evaluating a batch
    MagicNet.prototype.onFinishFold = function (f) { this.finish_fold_callback = f; };
    // called when a batch of candidates has finished evaluating
    MagicNet.prototype.onFinishBatch = function (f) { this.finish_batch_callback = f; };
    return MagicNet;
}());
exports.MagicNet = MagicNet;
;
//# sourceMappingURL=convnet_magicnet.js.map

/***/ }),
/* 15 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var convnet_vol_1 = __webpack_require__(1);
var uitl = __webpack_require__(0);
// Volume utilities
/**
 * intended for use with data augmentation
 * crop is the size of output
 * dx,dy are offset wrt incoming volume, of the shift
 * fliplr is boolean on whether we also want to flip left<->right
*/
function augment(V, crop, dx, dy, fliplr) {
    // note assumes square outputs of size crop x crop
    if (typeof (fliplr) === 'undefined') {
        fliplr = false;
    }
    if (typeof (dx) === 'undefined') {
        dx = uitl.randi(0, V.sx - crop);
    }
    if (typeof (dy) === 'undefined') {
        dy = uitl.randi(0, V.sy - crop);
    }
    // randomly sample a crop in the input volume
    var W;
    if (crop !== V.sx || dx !== 0 || dy !== 0) {
        W = new convnet_vol_1.Vol(crop, crop, V.depth, 0.0);
        for (var x = 0; x < crop; x++) {
            for (var y = 0; y < crop; y++) {
                if (x + dx < 0 || x + dx >= V.sx || y + dy < 0 || y + dy >= V.sy) {
                    continue;
                } // oob
                for (var d = 0; d < V.depth; d++) {
                    W.set(x, y, d, V.get(x + dx, y + dy, d)); // copy data over
                }
            }
        }
    }
    else {
        W = V;
    }
    if (fliplr) {
        // flip volume horziontally
        var W2 = W.cloneAndZero();
        for (var x = 0; x < W.sx; x++) {
            for (var y = 0; y < W.sy; y++) {
                for (var d = 0; d < W.depth; d++) {
                    W2.set(x, y, d, W.get(W.sx - x - 1, y, d)); // copy data over
                }
            }
        }
        W = W2; //swap
    }
    return W;
}
exports.augment = augment;
// img is a DOM element that contains a loaded image
// returns a Vol of size (W, H, 4). 4 is for RGBA
function img_to_vol(img, convert_grayscale) {
    if (typeof (convert_grayscale) === 'undefined') {
        convert_grayscale = false;
    }
    var canvas = document.createElement('canvas');
    canvas.width = img.width;
    canvas.height = img.height;
    var ctx = canvas.getContext("2d");
    // due to a Firefox bug
    try {
        ctx.drawImage(img, 0, 0);
    }
    catch (e) {
        if (e.name === "NS_ERROR_NOT_AVAILABLE") {
            // sometimes happens, lets just abort
            return false;
        }
        else {
            throw e;
        }
    }
    var img_data;
    try {
        img_data = ctx.getImageData(0, 0, canvas.width, canvas.height);
    }
    catch (e) {
        if (e.name === 'IndexSizeError') {
            return false; // not sure what causes this sometimes but okay abort
        }
        else {
            throw e;
        }
    }
    // prepare the input: get pixels and normalize them
    var p = img_data.data;
    var W = img.width;
    var H = img.height;
    var pv = [];
    for (var i = 0; i < p.length; i++) {
        pv.push(p[i] / 255.0 - 0.5); // normalize image pixels to [-0.5, 0.5]
    }
    var x = new convnet_vol_1.Vol(W, H, 4, 0.0); //input volume (image)
    x.w = pv;
    if (convert_grayscale) {
        // flatten into depth=1 array
        var x1 = new convnet_vol_1.Vol(W, H, 1, 0.0);
        for (var i = 0; i < W; i++) {
            for (var j = 0; j < H; j++) {
                x1.set(i, j, 0, x.get(i, j, 0));
            }
        }
        x = x1;
    }
    return x;
}
exports.img_to_vol = img_to_vol;
//# sourceMappingURL=convnet_vol_util.js.map

/***/ }),
/* 16 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var convnet_vol_1 = __webpack_require__(1);
var convnet_net_1 = __webpack_require__(4);
var index_1 = __webpack_require__(11);
/**
 * An agent is in state0 and does action0
 * environment then assigns reward0 and provides new state, state1
 * Experience nodes store all this information, which is used in the
 * Q-learning update step
 */
var Experience = (function () {
    function Experience(state0, action0, reward0, state1) {
        this.state0 = state0;
        this.action0 = action0;
        this.reward0 = reward0;
        this.state1 = state1;
    }
    return Experience;
}());
exports.Experience = Experience;
/**
 * A Brain object does all the magic.
 * over time it receives some inputs and some rewards
 * and its job is to set the outputs to maximize the expected reward
 */
var Brain = (function () {
    function Brain(num_states, num_actions, opt) {
        if (!opt) {
            opt = {};
        }
        // in number of time steps, of temporal memory
        // the ACTUAL input to the net will be (x,a) temporal_window times, and followed by current x
        // so to have no information from previous time step going into value function, set to 0.
        this.temporal_window = typeof opt.temporal_window !== 'undefined' ? opt.temporal_window : 1;
        // size of experience replay memory
        this.experience_size = typeof opt.experience_size !== 'undefined' ? opt.experience_size : 30000;
        // number of examples in experience replay memory before we begin learning
        this.start_learn_threshold = typeof opt.start_learn_threshold !== 'undefined' ? opt.start_learn_threshold : Math.floor(Math.min(this.experience_size * 0.1, 1000));
        // gamma is a crucial parameter that controls how much plan-ahead the agent does. In [0,1]
        this.gamma = typeof opt.gamma !== 'undefined' ? opt.gamma : 0.8;
        // number of steps we will learn for
        this.learning_steps_total = typeof opt.learning_steps_total !== 'undefined' ? opt.learning_steps_total : 100000;
        // how many steps of the above to perform only random actions (in the beginning)?
        this.learning_steps_burnin = typeof opt.learning_steps_burnin !== 'undefined' ? opt.learning_steps_burnin : 3000;
        // what epsilon value do we bottom out on? 0.0 => purely deterministic policy at end
        this.epsilon_min = typeof opt.epsilon_min !== 'undefined' ? opt.epsilon_min : 0.05;
        // what epsilon to use at test time? (i.e. when learning is disabled)
        this.epsilon_test_time = typeof opt.epsilon_test_time !== 'undefined' ? opt.epsilon_test_time : 0.01;
        // advanced feature. Sometimes a random action should be biased towards some values
        // for example in flappy bird, we may want to choose to not flap more often
        if (typeof opt.random_action_distribution !== 'undefined') {
            // this better sum to 1 by the way, and be of length this.num_actions
            this.random_action_distribution = opt.random_action_distribution;
            if (this.random_action_distribution.length !== num_actions) {
                console.log('TROUBLE. random_action_distribution should be same length as num_actions.');
            }
            var a = this.random_action_distribution;
            var s = 0.0;
            for (var k = 0; k < a.length; k++) {
                s += a[k];
            }
            if (Math.abs(s - 1.0) > 0.0001) {
                console.log('TROUBLE. random_action_distribution should sum to 1!');
            }
        }
        else {
            this.random_action_distribution = [];
        }
        // states that go into neural net to predict optimal action look as
        // x0,a0,x1,a1,x2,a2,...xt
        // this variable controls the size of that temporal window. Actions are
        // encoded as 1-of-k hot vectors
        this.net_inputs = num_states * this.temporal_window + num_actions * this.temporal_window + num_states;
        this.num_states = num_states;
        this.num_actions = num_actions;
        this.window_size = Math.max(this.temporal_window, 2); // must be at least 2, but if we want more context even more
        this.state_window = new Array(this.window_size);
        this.action_window = new Array(this.window_size);
        this.reward_window = new Array(this.window_size);
        this.net_window = new Array(this.window_size);
        // create [state -> value of all possible actions] modeling net for the value function
        var layer_defs = [];
        if (typeof opt.layer_defs !== 'undefined') {
            // this is an advanced usage feature, because size of the input to the network, and number of
            // actions must check out. This is not very pretty Object Oriented programming but I can't see
            // a way out of it :(
            layer_defs = opt.layer_defs;
            if (layer_defs.length < 2) {
                console.log('TROUBLE! must have at least 2 layers');
            }
            if (layer_defs[0].type !== 'input') {
                console.log('TROUBLE! first layer must be input layer!');
            }
            if (layer_defs[layer_defs.length - 1].type !== 'regression') {
                console.log('TROUBLE! last layer must be input regression!');
            }
            var inputlayerDef = layer_defs[0];
            if (inputlayerDef.out_depth * inputlayerDef.out_sx * inputlayerDef.out_sy !== this.net_inputs) {
                console.log('TROUBLE! Number of inputs must be num_states * temporal_window + num_actions * temporal_window + num_states!');
            }
            if (layer_defs[layer_defs.length - 1].num_neurons !== this.num_actions) {
                console.log('TROUBLE! Number of regression neurons should be num_actions!');
            }
        }
        else {
            // create a very simple neural net by default
            layer_defs.push({ type: 'input', out_sx: 1, out_sy: 1, out_depth: this.net_inputs });
            if (typeof opt.hidden_layer_sizes !== 'undefined') {
                // allow user to specify this via the option, for convenience
                var hl = opt.hidden_layer_sizes;
                for (var k = 0; k < hl.length; k++) {
                    layer_defs.push({ type: 'fc', num_neurons: hl[k], activation: 'relu' }); // relu by default
                }
            }
            layer_defs.push({ type: 'regression', num_neurons: num_actions }); // value function output
        }
        this.value_net = new convnet_net_1.Net();
        this.value_net.makeLayers(layer_defs);
        // and finally we need a Temporal Difference Learning trainer!
        var tdtrainer_options = { learning_rate: 0.01, momentum: 0.0, batch_size: 64, l2_decay: 0.01 };
        if (typeof opt.tdtrainer_options !== 'undefined') {
            tdtrainer_options = opt.tdtrainer_options; // allow user to overwrite this
        }
        this.tdtrainer = new index_1.SGDTrainer(this.value_net, tdtrainer_options);
        // experience replay
        this.experience = [];
        // various housekeeping variables
        this.age = 0; // incremented every backward()
        this.forward_passes = 0; // incremented every forward()
        this.epsilon = 1.0; // controls exploration exploitation tradeoff. Should be annealed over time
        this.latest_reward = 0;
        this.last_input_array = [];
        this.average_reward_window = new index_1.cnnutil.Window(1000, 10);
        this.average_loss_window = new index_1.cnnutil.Window(1000, 10);
        this.learning = true;
    }
    Brain.prototype.random_action = function () {
        // a bit of a helper function. It returns a random action
        // we are abstracting this away because in future we may want to
        // do more sophisticated things. For example some actions could be more
        // or less likely at "rest"/default state.
        if (this.random_action_distribution.length === 0) {
            return index_1.util.randi(0, this.num_actions);
        }
        else {
            // okay, lets do some fancier sampling:
            var p = index_1.util.randf(0, 1.0);
            var cumprob = 0.0;
            for (var k = 0; k < this.num_actions; k++) {
                cumprob += this.random_action_distribution[k];
                if (p < cumprob) {
                    return k;
                }
            }
        }
    };
    Brain.prototype.policy = function (s) {
        // compute the value of doing any action in this state
        // and return the argmax action and its value
        var svol = new convnet_vol_1.Vol(1, 1, this.net_inputs);
        svol.w = s;
        var action_values = this.value_net.forward(svol);
        var maxk = 0;
        var maxval = action_values.w[0];
        for (var k = 1; k < this.num_actions; k++) {
            if (action_values.w[k] > maxval) {
                maxk = k;
                maxval = action_values.w[k];
            }
        }
        return { action: maxk, value: maxval };
    };
    Brain.prototype.getNetInput = function (xt) {
        // return s = (x,a,x,a,x,a,xt) state vector.
        // It's a concatenation of last window_size (x,a) pairs and current state x
        var w = [];
        w = w.concat(xt); // start with current state
        // and now go backwards and append states and actions from history temporal_window times
        var n = this.window_size;
        for (var k = 0; k < this.temporal_window; k++) {
            // state
            w = w.concat(this.state_window[n - 1 - k]);
            // action, encoded as 1-of-k indicator vector. We scale it up a bit because
            // we dont want weight regularization to undervalue this information, as it only exists once
            var action1ofk = new Array(this.num_actions);
            for (var q = 0; q < this.num_actions; q++) {
                action1ofk[q] = 0.0;
            }
            action1ofk[this.action_window[n - 1 - k]] = 1.0 * this.num_states;
            w = w.concat(action1ofk);
        }
        return w;
    };
    Brain.prototype.forward = function (input_array) {
        // compute forward (behavior) pass given the input neuron signals from body
        this.forward_passes += 1;
        this.last_input_array = input_array; // back this up
        // create network input
        var action;
        var net_input;
        if (this.forward_passes > this.temporal_window) {
            // we have enough to actually do something reasonable
            net_input = this.getNetInput(input_array);
            if (this.learning) {
                // compute epsilon for the epsilon-greedy policy
                this.epsilon = Math.min(1.0, Math.max(this.epsilon_min, 1.0 - (this.age - this.learning_steps_burnin) / (this.learning_steps_total - this.learning_steps_burnin)));
            }
            else {
                this.epsilon = this.epsilon_test_time; // use test-time value
            }
            var rf = index_1.util.randf(0, 1);
            if (rf < this.epsilon) {
                // choose a random action with epsilon probability
                action = this.random_action();
            }
            else {
                // otherwise use our policy to make decision
                var maxact = this.policy(net_input);
                action = maxact.action;
            }
        }
        else {
            // pathological case that happens first few iterations
            // before we accumulate window_size inputs
            // const net_input = [] as number[]; // never used
            action = this.random_action();
        }
        // remember the state and action we took for backward pass
        this.net_window.shift();
        this.net_window.push(net_input);
        this.state_window.shift();
        this.state_window.push(input_array);
        this.action_window.shift();
        this.action_window.push(action);
        return action;
    };
    Brain.prototype.backward = function (reward) {
        this.latest_reward = reward;
        this.average_reward_window.add(reward);
        this.reward_window.shift();
        this.reward_window.push(reward);
        if (!this.learning) {
            return;
        }
        // various book-keeping
        this.age += 1;
        // it is time t+1 and we have to store (s_t, a_t, r_t, s_{t+1}) as new experience
        // (given that an appropriate number of state measurements already exist, of course)
        if (this.forward_passes > this.temporal_window + 1) {
            var e = new Experience();
            var n = this.window_size;
            e.state0 = this.net_window[n - 2];
            e.action0 = this.action_window[n - 2];
            e.reward0 = this.reward_window[n - 2];
            e.state1 = this.net_window[n - 1];
            if (this.experience.length < this.experience_size) {
                this.experience.push(e);
            }
            else {
                // replace. finite memory!
                var ri = index_1.util.randi(0, this.experience_size);
                this.experience[ri] = e;
            }
        }
        // learn based on experience, once we have some samples to go on
        // this is where the magic happens...
        if (this.experience.length > this.start_learn_threshold) {
            var avcost = 0.0;
            for (var k = 0; k < this.tdtrainer.batch_size; k++) {
                var re = index_1.util.randi(0, this.experience.length);
                var e = this.experience[re];
                var x = new convnet_vol_1.Vol(1, 1, this.net_inputs);
                x.w = e.state0;
                var maxact = this.policy(e.state1);
                var r = e.reward0 + this.gamma * maxact.value;
                var ystruct = { dim: e.action0, val: r };
                var loss = this.tdtrainer.train(x, ystruct);
                avcost += loss.loss;
            }
            avcost = avcost / this.tdtrainer.batch_size;
            this.average_loss_window.add(avcost);
        }
    };
    Brain.prototype.visSelf = function (elt) {
        elt.innerHTML = ''; // erase elt first
        // elt is a DOM element that this function fills with brain-related information
        var brainvis = document.createElement('div');
        // basic information
        var desc = document.createElement('div');
        var t = '';
        t += 'experience replay size: ' + this.experience.length + '<br>';
        t += 'exploration epsilon: ' + this.epsilon + '<br>';
        t += 'age: ' + this.age + '<br>';
        t += 'average Q-learning loss: ' + this.average_loss_window.get_average() + '<br />';
        t += 'smooth-ish reward: ' + this.average_reward_window.get_average() + '<br />';
        desc.innerHTML = t;
        brainvis.appendChild(desc);
        elt.appendChild(brainvis);
    };
    return Brain;
}());
exports.Brain = Brain;
//# sourceMappingURL=deepqlearn.js.map

/***/ }),
/* 17 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var tslib_1 = __webpack_require__(3);
var layers_1 = __webpack_require__(2);
var util = __webpack_require__(0);
var getopt = util.getopt;
var InputLayer = (function (_super) {
    tslib_1.__extends(InputLayer, _super);
    function InputLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        _this = _super.call(this, opt) || this;
        // required: depth
        _this.out_depth = getopt(opt, ['out_depth', 'depth'], 0);
        // optional: default these dimensions to 1
        _this.out_sx = getopt(opt, ['out_sx', 'sx', 'width'], 1);
        _this.out_sy = getopt(opt, ['out_sy', 'sy', 'height'], 1);
        // computed
        _this.layer_type = 'input';
        return _this;
    }
    InputLayer.prototype.forward = function (V) {
        this.in_act = V;
        this.out_act = V;
        return this.out_act; // simply identity function for now
    };
    InputLayer.prototype.backward = function () { };
    InputLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    InputLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        return json;
    };
    InputLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
    };
    return InputLayer;
}(layers_1.LayerBase));
exports.InputLayer = InputLayer;
//# sourceMappingURL=convnet_layers_input.js.map

/***/ }),
/* 18 */
/***/ (function(module, exports, __webpack_require__) {

Object.defineProperty(exports, "__esModule", { value: true });
var tslib_1 = __webpack_require__(3);
var convnet_vol_1 = __webpack_require__(1);
var layers_1 = __webpack_require__(2);
var util = __webpack_require__(0);
var OutputLayer = (function (_super) {
    tslib_1.__extends(OutputLayer, _super);
    function OutputLayer(opt) {
        var _this = _super.call(this, opt) || this;
        _this.out_sx = opt.in_sx;
        _this.out_sy = opt.in_sy;
        _this.out_depth = opt.in_depth;
        return _this;
    }
    return OutputLayer;
}(layers_1.LayerBase));
exports.OutputLayer = OutputLayer;
/**
 * Implements ReLU nonlinearity elementwise
 * x -> max(0, x)
 * the output is in [0, inf)
 */
var ReluLayer = (function (_super) {
    tslib_1.__extends(ReluLayer, _super);
    function ReluLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        _this = _super.call(this, opt) || this;
        // computed
        _this.layer_type = 'relu';
        return _this;
    }
    ReluLayer.prototype.forward = function (V) {
        this.in_act = V;
        var V2 = V.clone();
        var N = V.w.length;
        var V2w = V2.w;
        for (var i = 0; i < N; i++) {
            if (V2w[i] < 0) {
                V2w[i] = 0; // threshold at 0
            }
            this.out_act = V2;
            return this.out_act;
        }
    };
    ReluLayer.prototype.backward = function () {
        var V = this.in_act; // we need to set dw of this
        var V2 = this.out_act;
        var N = V.w.length;
        V.dw = util.zeros(N); // zero out gradient wrt data
        for (var i = 0; i < N; i++) {
            if (V2.w[i] <= 0) {
                V.dw[i] = 0; // threshold
            }
            else {
                V.dw[i] = V2.dw[i];
            }
        }
    };
    ReluLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    ReluLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        return json;
    };
    ReluLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
    };
    return ReluLayer;
}(OutputLayer));
exports.ReluLayer = ReluLayer;
/**
 * Implements Sigmoid nnonlinearity elementwise
 * x -> 1/(1+e^(-x))
 * so the output is between 0 and 1.
 */
var SigmoidLayer = (function (_super) {
    tslib_1.__extends(SigmoidLayer, _super);
    function SigmoidLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        _this = _super.call(this, opt) || this;
        // computed
        _this.layer_type = 'sigmoid';
        return _this;
    }
    SigmoidLayer.prototype.forward = function (V) {
        this.in_act = V;
        var V2 = V.cloneAndZero();
        var N = V.w.length;
        var V2w = V2.w;
        var Vw = V.w;
        for (var i = 0; i < N; i++) {
            V2w[i] = 1.0 / (1.0 + Math.exp(-Vw[i]));
        }
        this.out_act = V2;
        return this.out_act;
    };
    SigmoidLayer.prototype.backward = function () {
        var V = this.in_act; // we need to set dw of this
        var V2 = this.out_act;
        var N = V.w.length;
        V.dw = util.zeros(N); // zero out gradient wrt data
        for (var i = 0; i < N; i++) {
            var v2wi = V2.w[i];
            V.dw[i] = v2wi * (1.0 - v2wi) * V2.dw[i];
        }
    };
    SigmoidLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    SigmoidLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        return json;
    };
    SigmoidLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
    };
    return SigmoidLayer;
}(OutputLayer));
exports.SigmoidLayer = SigmoidLayer;
// Implements Maxout nnonlinearity that computes
// x -> max(x)
// where x is a vector of size group_size. Ideally of course,
// the input size should be exactly divisible by group_size
var MaxoutLayer = (function (_super) {
    tslib_1.__extends(MaxoutLayer, _super);
    function MaxoutLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        var mopt = opt;
        _this = _super.call(this, mopt) || this;
        // required
        _this.group_size = typeof mopt.group_size !== 'undefined' ? mopt.group_size : 2;
        // computed
        _this.out_depth = Math.floor(mopt.in_depth / _this.group_size);
        _this.layer_type = 'maxout';
        _this.switches = util.zeros(_this.out_sx * _this.out_sy * _this.out_depth); // useful for backprop
        return _this;
    }
    MaxoutLayer.prototype.forward = function (V) {
        this.in_act = V;
        var N = this.out_depth;
        var V2 = new convnet_vol_1.Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);
        // optimization branch. If we're operating on 1D arrays we dont have
        // to worry about keeping track of x,y,d coordinates inside
        // input volumes. In convnets we do :(
        if (this.out_sx === 1 && this.out_sy === 1) {
            for (var i = 0; i < N; i++) {
                var ix = i * this.group_size; // base index offset
                var a = V.w[ix];
                var ai = 0;
                for (var j = 1; j < this.group_size; j++) {
                    var a2 = V.w[ix + j];
                    if (a2 > a) {
                        a = a2;
                        ai = j;
                    }
                }
                V2.w[i] = a;
                this.switches[i] = ix + ai;
            }
        }
        else {
            var n = 0; // counter for switches
            for (var x = 0; x < V.sx; x++) {
                for (var y = 0; y < V.sy; y++) {
                    for (var i = 0; i < N; i++) {
                        var ix = i * this.group_size;
                        var a = V.get(x, y, ix);
                        var ai = 0;
                        for (var j = 1; j < this.group_size; j++) {
                            var a2 = V.get(x, y, ix + j);
                            if (a2 > a) {
                                a = a2;
                                ai = j;
                            }
                        }
                        V2.set(x, y, i, a);
                        this.switches[n] = ix + ai;
                        n++;
                    }
                }
            }
        }
        this.out_act = V2;
        return this.out_act;
    };
    MaxoutLayer.prototype.backward = function () {
        var V = this.in_act; // we need to set dw of this
        var V2 = this.out_act;
        var N = this.out_depth;
        V.dw = util.zeros(V.w.length); // zero out gradient wrt data
        // pass the gradient through the appropriate switch
        if (this.out_sx === 1 && this.out_sy === 1) {
            for (var i = 0; i < N; i++) {
                var chain_grad = V2.dw[i];
                V.dw[this.switches[i]] = chain_grad;
            }
        }
        else {
            // bleh okay, lets do this the hard way
            var n = 0; // counter for switches
            for (var x = 0; x < V2.sx; x++) {
                for (var y = 0; y < V2.sy; y++) {
                    for (var i = 0; i < N; i++) {
                        var chain_grad = V2.get_grad(x, y, i);
                        V.set_grad(x, y, this.switches[n], chain_grad);
                        n++;
                    }
                }
            }
        }
    };
    MaxoutLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    MaxoutLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        json.group_size = this.group_size;
        return json;
    };
    MaxoutLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
        this.group_size = json.group_size;
        this.switches = util.zeros(this.group_size);
    };
    return MaxoutLayer;
}(OutputLayer));
exports.MaxoutLayer = MaxoutLayer;
/**
 * a helper function, since tanh is not yet part of ECMAScript. Will be in v6.
 */
function tanh(x) {
    var y = Math.exp(2 * x);
    return (y - 1) / (y + 1);
}
// Implements Tanh nnonlinearity elementwise
// x -> tanh(x)
// so the output is between -1 and 1.
var TanhLayer = (function (_super) {
    tslib_1.__extends(TanhLayer, _super);
    function TanhLayer(opt) {
        var _this = this;
        if (!opt) {
            return;
        }
        _this = _super.call(this, opt) || this;
        // computed
        _this.layer_type = 'tanh';
        return _this;
    }
    TanhLayer.prototype.forward = function (V) {
        this.in_act = V;
        var V2 = V.cloneAndZero();
        var N = V.w.length;
        for (var i = 0; i < N; i++) {
            V2.w[i] = tanh(V.w[i]);
        }
        this.out_act = V2;
        return this.out_act;
    };
    TanhLayer.prototype.backward = function () {
        var V = this.in_act; // we need to set dw of this
        var V2 = this.out_act;
        var N = V.w.length;
        V.dw = util.zeros(N); // zero out gradient wrt data
        for (var i = 0; i < N; i++) {
            var v2wi = V2.w[i];
            V.dw[i] = (1.0 - v2wi * v2wi) * V2.dw[i];
        }
    };
    TanhLayer.prototype.getParamsAndGrads = function () {
        return [];
    };
    TanhLayer.prototype.toJSON = function () {
        var json = {};
        json.out_depth = this.out_depth;
        json.out_sx = this.out_sx;
        json.out_sy = this.out_sy;
        json.layer_type = this.layer_type;
        return json;
    };
    TanhLayer.prototype.fromJSON = function (json) {
        this.out_depth = json.out_depth;
        this.out_sx = json.out_sx;
        this.out_sy = json.out_sy;
        this.layer_type = json.layer_type;
    };
    return TanhLayer;
}(OutputLayer));
exports.TanhLayer = TanhLayer;
//# sourceMappingURL=convnet_layers_nonlinearities.js.map

/***/ })
/******/ ]);